{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56cbba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import h5py\n",
    "import torch.nn as nn\n",
    "\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "\n",
    "#################################################\n",
    "#\n",
    "# Utilities\n",
    "#\n",
    "#################################################\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# reading data\n",
    "class MatReader(object):\n",
    "    def __init__(self, file_path, to_torch=True, to_cuda=False, to_float=True):\n",
    "        super(MatReader, self).__init__()\n",
    "\n",
    "        self.to_torch = to_torch\n",
    "        self.to_cuda = to_cuda\n",
    "        self.to_float = to_float\n",
    "\n",
    "        self.file_path = file_path\n",
    "\n",
    "        self.data = None\n",
    "        self.old_mat = None\n",
    "        self._load_file()\n",
    "\n",
    "    def _load_file(self):\n",
    "        try:\n",
    "            self.data = scipy.io.loadmat(self.file_path)\n",
    "            self.old_mat = True\n",
    "        except:\n",
    "            self.data = h5py.File(self.file_path)\n",
    "            self.old_mat = False\n",
    "\n",
    "    def load_file(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self._load_file()\n",
    "\n",
    "    def read_field(self, field):\n",
    "        x = self.data[field]\n",
    "\n",
    "        if not self.old_mat:\n",
    "            x = x[()]\n",
    "            x = np.transpose(x, axes=range(len(x.shape) - 1, -1, -1))\n",
    "\n",
    "        if self.to_float:\n",
    "            x = x.astype(np.float32)\n",
    "\n",
    "        if self.to_torch:\n",
    "            x = torch.from_numpy(x)\n",
    "\n",
    "            if self.to_cuda:\n",
    "                x = x.cuda()\n",
    "\n",
    "        return x\n",
    "\n",
    "    def set_cuda(self, to_cuda):\n",
    "        self.to_cuda = to_cuda\n",
    "\n",
    "    def set_torch(self, to_torch):\n",
    "        self.to_torch = to_torch\n",
    "\n",
    "    def set_float(self, to_float):\n",
    "        self.to_float = to_float\n",
    "\n",
    "\n",
    "class UnitGaussianNormalizer:\n",
    "    def __init__(self, x, eps=1e-5):\n",
    "\n",
    "        self.mean = torch.mean(x, 0).view(-1)\n",
    "        self.std = torch.std(x, 0).view(-1)\n",
    "\n",
    "        self.eps = eps\n",
    "\n",
    "    def encode(self, x):\n",
    "        s = x.size()\n",
    "        x = x.view(s[0], -1)\n",
    "        x = (x - self.mean) / (self.std + self.eps)\n",
    "        x = x.view(s)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, sample_idx=None):\n",
    "        if sample_idx is None:\n",
    "            std = self.std + self.eps  # n\n",
    "            mean = self.mean\n",
    "        else:\n",
    "            std = self.std[sample_idx] + self.eps  # batch * n\n",
    "            mean = self.mean[sample_idx]\n",
    "\n",
    "        s = x.size()\n",
    "        x = x.view(s[0], -1)\n",
    "        x = (x * std) + mean\n",
    "        x = x.view(s)\n",
    "        return x\n",
    "\n",
    "    def cuda(self):\n",
    "        self.mean = self.mean.cuda()\n",
    "        self.std = self.std.cuda()\n",
    "\n",
    "    def cpu(self):\n",
    "        self.mean = self.mean.cpu()\n",
    "        self.std = self.std.cpu()\n",
    "\n",
    "\n",
    "# normalization, pointwise gaussian\n",
    "class UnitGaussianNormalizer_Siavash(object):\n",
    "    def __init__(self, x):\n",
    "        super(UnitGaussianNormalizer_Siavash, self).__init__()\n",
    "\n",
    "        # x could be in shape of ntrain*n or ntrain*T*n or ntrain*n*T\n",
    "        self.mean = torch.mean(x, 0)\n",
    "        self.std = torch.std(x, 0)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = (x - self.mean) / (self.std)\n",
    "        x = torch.nan_to_num(x, nan=0.0)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, sample_idx=None):\n",
    "        if sample_idx is None:\n",
    "            std = self.std  # n\n",
    "            mean = self.mean\n",
    "        else:\n",
    "            if len(self.mean.shape) == len(sample_idx[0].shape):\n",
    "                std = self.std[sample_idx]  # batch*n\n",
    "                mean = self.mean[sample_idx]\n",
    "            if len(self.mean.shape) > len(sample_idx[0].shape):\n",
    "                std = self.std[:, sample_idx]  # T*batch*n\n",
    "                mean = self.mean[:, sample_idx]\n",
    "\n",
    "        # x is in shape of batch*n or T*batch*n\n",
    "        x = (x * std) + mean\n",
    "        return x\n",
    "\n",
    "    def cuda(self):\n",
    "        self.mean = self.mean.cuda()\n",
    "        self.std = self.std.cuda()\n",
    "\n",
    "    def cpu(self):\n",
    "        self.mean = self.mean.cpu()\n",
    "        self.std = self.std.cpu()\n",
    "\n",
    "\n",
    "# normalization, Gaussian\n",
    "class GaussianNormalizer(object):\n",
    "    def __init__(self, x, eps=0.00001):\n",
    "        super(GaussianNormalizer, self).__init__()\n",
    "\n",
    "        self.mean = torch.mean(x)\n",
    "        self.std = torch.std(x)\n",
    "        self.eps = eps\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = (x - self.mean) / (self.std + self.eps)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, sample_idx=None):\n",
    "        x = (x * (self.std + self.eps)) + self.mean\n",
    "        return x\n",
    "\n",
    "    def cuda(self):\n",
    "        self.mean = self.mean.cuda()\n",
    "        self.std = self.std.cuda()\n",
    "\n",
    "    def cpu(self):\n",
    "        self.mean = self.mean.cpu()\n",
    "        self.std = self.std.cpu()\n",
    "\n",
    "\n",
    "# normalization, scaling by range\n",
    "class RangeNormalizer(object):\n",
    "    def __init__(self, x, low=0.0, high=1.0):\n",
    "        super(RangeNormalizer, self).__init__()\n",
    "        mymin = torch.min(x, 0)[0].view(-1)\n",
    "        mymax = torch.max(x, 0)[0].view(-1)\n",
    "\n",
    "        self.a = (high - low) / (mymax - mymin)\n",
    "        self.b = -self.a * mymax + high\n",
    "\n",
    "    def encode(self, x):\n",
    "        s = x.size()\n",
    "        x = x.view(s[0], -1)\n",
    "        x = self.a * x + self.b\n",
    "        x = x.view(s)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x):\n",
    "        s = x.size()\n",
    "        x = x.view(s[0], -1)\n",
    "        x = (x - self.b) / self.a\n",
    "        x = x.view(s)\n",
    "        return x\n",
    "\n",
    "\n",
    "# loss function with rel/abs Lp loss\n",
    "class LpLoss_Siavash(object):\n",
    "    def __init__(self, d=2, p=2, damage=False, size_average=True, reduction=True):\n",
    "        super(LpLoss_Siavash, self).__init__()\n",
    "\n",
    "        # Dimension and Lp-norm type are postive\n",
    "        assert d > 0 and p > 0\n",
    "\n",
    "        self.d = d\n",
    "        self.p = p\n",
    "        self.damage = damage\n",
    "        self.reduction = reduction\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def abs(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        # Assume uniform mesh\n",
    "        h = 1.0 / (x.size()[1] - 1.0)\n",
    "\n",
    "        all_norms = (h ** (self.d / self.p)) * torch.norm(x.view(num_examples, -1) - y.view(num_examples, -1), self.p,\n",
    "                                                          1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(all_norms)\n",
    "            else:\n",
    "                return torch.sum(all_norms)\n",
    "\n",
    "        return all_norms\n",
    "\n",
    "    def rel(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        diff_norms = torch.norm(x.reshape(num_examples, -1) - y.reshape(num_examples, -1), self.p, 1)\n",
    "        if self.damage:\n",
    "            y_norms = 1.0\n",
    "        else:\n",
    "            y_norms = torch.norm(y.reshape(num_examples, -1), self.p, 1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(diff_norms ** 2.0 / y_norms ** 2.0)\n",
    "            else:\n",
    "                return torch.sum(diff_norms ** 2.0 / y_norms ** 2.0)\n",
    "\n",
    "        return diff_norms ** 2.0 / y_norms ** 2.0\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        return self.rel(x, y)\n",
    "\n",
    "\n",
    "class LpLoss(object):\n",
    "    def __init__(self, d=2, p=2, size_average=True, reduction=True):\n",
    "        super(LpLoss, self).__init__()\n",
    "\n",
    "        #Dimension and Lp-norm type are postive\n",
    "        assert d > 0 and p > 0\n",
    "\n",
    "        self.d = d\n",
    "        self.p = p\n",
    "        self.reduction = reduction\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def abs(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        #Assume uniform mesh\n",
    "        h = 1.0 / (x.size()[1] - 1.0)\n",
    "\n",
    "        all_norms = (h**(self.d/self.p))*torch.norm(x.view(num_examples,-1) - y.view(num_examples,-1), self.p, 1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(all_norms)\n",
    "            else:\n",
    "                return torch.sum(all_norms)\n",
    "\n",
    "        return all_norms\n",
    "\n",
    "    def rel(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        diff_norms = torch.norm(x.reshape(num_examples,-1) - y.reshape(num_examples,-1), self.p, 1)\n",
    "        y_norms = torch.norm(y.reshape(num_examples,-1), self.p, 1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(diff_norms/y_norms)\n",
    "            else:\n",
    "                return torch.sum(diff_norms/y_norms)\n",
    "\n",
    "        return diff_norms/y_norms\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        return self.rel(x, y)\n",
    "\n",
    "\n",
    "# Sobolev norm (HS norm)\n",
    "# where we also compare the numerical derivatives between the output and target\n",
    "class HsLoss(object):\n",
    "    def __init__(self, d=2, p=2, k=1, a=None, group=False, size_average=True, reduction=True):\n",
    "        super(HsLoss, self).__init__()\n",
    "\n",
    "        # Dimension and Lp-norm type are postive\n",
    "        assert d > 0 and p > 0\n",
    "\n",
    "        self.d = d\n",
    "        self.p = p\n",
    "        self.k = k\n",
    "        self.balanced = group\n",
    "        self.reduction = reduction\n",
    "        self.size_average = size_average\n",
    "\n",
    "        if a == None:\n",
    "            a = [1, ] * k\n",
    "        self.a = a\n",
    "\n",
    "    def rel(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "        diff_norms = torch.norm(x.reshape(num_examples, -1) - y.reshape(num_examples, -1), self.p, 1)\n",
    "        y_norms = torch.norm(y.reshape(num_examples, -1), self.p, 1)\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(diff_norms / y_norms)\n",
    "            else:\n",
    "                return torch.sum(diff_norms / y_norms)\n",
    "        return diff_norms / y_norms\n",
    "\n",
    "    def __call__(self, x, y, a=None):\n",
    "        nx = x.size()[1]\n",
    "        ny = x.size()[2]\n",
    "        k = self.k\n",
    "        balanced = self.balanced\n",
    "        a = self.a\n",
    "        x = x.view(x.shape[0], nx, ny, -1)\n",
    "        y = y.view(y.shape[0], nx, ny, -1)\n",
    "\n",
    "        k_x = torch.cat((torch.arange(start=0, end=nx // 2, step=1), torch.arange(start=-nx // 2, end=0, step=1)),\n",
    "                        0).reshape(nx, 1).repeat(1, ny)\n",
    "        k_y = torch.cat((torch.arange(start=0, end=ny // 2, step=1), torch.arange(start=-ny // 2, end=0, step=1)),\n",
    "                        0).reshape(1, ny).repeat(nx, 1)\n",
    "        k_x = torch.abs(k_x).reshape(1, nx, ny, 1).to(x.device)\n",
    "        k_y = torch.abs(k_y).reshape(1, nx, ny, 1).to(x.device)\n",
    "\n",
    "        x = torch.fft.fftn(x, dim=[1, 2])\n",
    "        y = torch.fft.fftn(y, dim=[1, 2])\n",
    "\n",
    "        if balanced == False:\n",
    "            weight = 1\n",
    "            if k >= 1:\n",
    "                weight += a[0] ** 2 * (k_x ** 2 + k_y ** 2)\n",
    "            if k >= 2:\n",
    "                weight += a[1] ** 2 * (k_x ** 4 + 2 * k_x ** 2 * k_y ** 2 + k_y ** 4)\n",
    "            weight = torch.sqrt(weight)\n",
    "            loss = self.rel(x * weight, y * weight)\n",
    "        else:\n",
    "            loss = self.rel(x, y)\n",
    "            if k >= 1:\n",
    "                weight = a[0] * torch.sqrt(k_x ** 2 + k_y ** 2)\n",
    "                loss += self.rel(x * weight, y * weight)\n",
    "            if k >= 2:\n",
    "                weight = a[1] * torch.sqrt(k_x ** 4 + 2 * k_x ** 2 * k_y ** 2 + k_y ** 4)\n",
    "                loss += self.rel(x * weight, y * weight)\n",
    "            loss = loss / (k + 1)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "# Error\n",
    "class Error(object):\n",
    "    def __init__(self, p=2, field=True, relative=True, mean=False):\n",
    "        super(Error, self).__init__()\n",
    "\n",
    "        # Dimension and Lp-norm type are postive\n",
    "        assert p > 0\n",
    "\n",
    "        self.p = p\n",
    "        self.relative = relative\n",
    "        self.field = field\n",
    "        self.mean = mean\n",
    "\n",
    "    def absolute(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        if self.field:\n",
    "            error = torch.abs(x - y)\n",
    "            if self.mean:\n",
    "                error = torch.mean(error, 0)\n",
    "            else:\n",
    "                error = torch.sum(error, 0)\n",
    "        else:\n",
    "            error = torch.norm(x.view(num_examples, -1) - y.view(num_examples, -1), self.p, 1)\n",
    "            if self.mean:\n",
    "                error = torch.mean(error, 0)\n",
    "            else:\n",
    "                error = torch.sum(error, 0)\n",
    "        return error\n",
    "\n",
    "    def rel(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        if self.field:\n",
    "            error = torch.abs(x - y) / torch.max(torch.abs(y))\n",
    "            if self.mean:\n",
    "                error = torch.mean(error, 0)\n",
    "            else:\n",
    "                error = torch.sum(error, 0)\n",
    "        else:\n",
    "            error = torch.norm(x.view(num_examples, -1) - y.view(num_examples, -1), self.p, 1) / torch.norm(\n",
    "                y.view(num_examples, -1), self.p, 1)\n",
    "            if self.mean:\n",
    "                error = torch.mean(error, 0)\n",
    "            else:\n",
    "                error = torch.sum(error, 0)\n",
    "        return error\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        if self.relative:\n",
    "            return self.rel(x, y)\n",
    "        else:\n",
    "            return self.absolute(x, y)\n",
    "\n",
    "\n",
    "# A simple feedforward neural network\n",
    "class DenseNet(torch.nn.Module):\n",
    "    def __init__(self, layers, nonlinearity, out_nonlinearity=None, normalize=False):\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        self.n_layers = len(layers) - 1\n",
    "\n",
    "        assert self.n_layers >= 1\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        for j in range(self.n_layers):\n",
    "            self.layers.append(nn.Linear(layers[j], layers[j + 1]))\n",
    "\n",
    "            if j != self.n_layers - 1:\n",
    "                if normalize:\n",
    "                    self.layers.append(nn.BatchNorm1d(layers[j + 1]))\n",
    "\n",
    "                self.layers.append(nonlinearity())\n",
    "\n",
    "        if out_nonlinearity is not None:\n",
    "            self.layers.append(out_nonlinearity())\n",
    "\n",
    "    def forward(self, x):\n",
    "        for _, l in enumerate(self.layers):\n",
    "            x = l(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# print the number of parameters\n",
    "def count_params(model):\n",
    "    c = 0\n",
    "    for p in list(model.parameters()):\n",
    "        c += reduce(operator.mul,\n",
    "                    list(p.size()+(2,) if p.is_complex() else p.size()))\n",
    "    return c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
