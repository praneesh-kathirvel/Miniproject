{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5a91d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b153a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('donut_data.pkl', 'rb') as file:\n",
    "    data_list = pickle.load(file)\n",
    "    \n",
    "with open('donut_data_coord_grid.pkl', 'rb') as file:\n",
    "    coord_grid = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2fb67a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_data = len(data_list)\n",
    "# split data \n",
    "data_train, data_test, data_val = data_list[0:1000], data_list[1000:1100], data_list[1100:1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ed9d564",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        ],\n",
       "        [0.        , 0.01538462],\n",
       "        [0.        , 0.03076923],\n",
       "        ...,\n",
       "        [0.        , 0.96923077],\n",
       "        [0.        , 0.98461538],\n",
       "        [0.        , 1.        ]],\n",
       "\n",
       "       [[0.01538462, 0.        ],\n",
       "        [0.01538462, 0.01538462],\n",
       "        [0.01538462, 0.03076923],\n",
       "        ...,\n",
       "        [0.01538462, 0.96923077],\n",
       "        [0.01538462, 0.98461538],\n",
       "        [0.01538462, 1.        ]],\n",
       "\n",
       "       [[0.03076923, 0.        ],\n",
       "        [0.03076923, 0.01538462],\n",
       "        [0.03076923, 0.03076923],\n",
       "        ...,\n",
       "        [0.03076923, 0.96923077],\n",
       "        [0.03076923, 0.98461538],\n",
       "        [0.03076923, 1.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.96923077, 0.        ],\n",
       "        [0.96923077, 0.01538462],\n",
       "        [0.96923077, 0.03076923],\n",
       "        ...,\n",
       "        [0.96923077, 0.96923077],\n",
       "        [0.96923077, 0.98461538],\n",
       "        [0.96923077, 1.        ]],\n",
       "\n",
       "       [[0.98461538, 0.        ],\n",
       "        [0.98461538, 0.01538462],\n",
       "        [0.98461538, 0.03076923],\n",
       "        ...,\n",
       "        [0.98461538, 0.96923077],\n",
       "        [0.98461538, 0.98461538],\n",
       "        [0.98461538, 1.        ]],\n",
       "\n",
       "       [[1.        , 0.        ],\n",
       "        [1.        , 0.01538462],\n",
       "        [1.        , 0.03076923],\n",
       "        ...,\n",
       "        [1.        , 0.96923077],\n",
       "        [1.        , 0.98461538],\n",
       "        [1.        , 1.        ]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4594597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://github.com/EmilienDupont/coin\n",
    "from math import sqrt\n",
    "\n",
    "import einops\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "#from coral.utils.interpolate import knn_interpolate_custom, rescale_coordinate\n",
    "\n",
    "\n",
    "class Sine(nn.Module):\n",
    "    \"\"\"Sine activation with scaling.\n",
    "\n",
    "    Args:\n",
    "        w0 (float): Omega_0 parameter from SIREN paper.\n",
    "    \"\"\"\n",
    "    def __init__(self, w0=1.0):\n",
    "        super().__init__()\n",
    "        self.w0 = w0\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sin(self.w0 * x)\n",
    "\n",
    "\n",
    "class SirenLayer(nn.Module):\n",
    "    \"\"\"Implements a single SIREN layer.\n",
    "\n",
    "    Args:\n",
    "        dim_in (int): Dimension of input.\n",
    "        dim_out (int): Dimension of output.\n",
    "        w0 (float):\n",
    "        c (float): c value from SIREN paper used for weight initialization.\n",
    "        is_first (bool): Whether this is first layer of model.\n",
    "        is_last (bool): Whether this is last layer of model. If it is, no\n",
    "            activation is applied and 0.5 is added to the output. Since we\n",
    "            assume all training data lies in [0, 1], this allows for centering\n",
    "            the output of the model.\n",
    "        use_bias (bool): Whether to learn bias in linear layer.\n",
    "        activation (torch.nn.Module): Activation function. If None, defaults to\n",
    "            Sine activation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_in,\n",
    "        dim_out,\n",
    "        w0=30.0,\n",
    "        c=6.0,\n",
    "        is_first=False,\n",
    "        is_last=False,\n",
    "        use_bias=True,\n",
    "        activation=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_out = dim_out\n",
    "        self.is_first = is_first\n",
    "        self.is_last = is_last\n",
    "\n",
    "        self.linear = nn.Linear(dim_in, dim_out, bias=use_bias)\n",
    "\n",
    "        # Initialize layers following SIREN paper\n",
    "        w_std = (1 / dim_in) if self.is_first else (sqrt(c / dim_in) / w0)\n",
    "        nn.init.uniform_(self.linear.weight, -w_std, w_std)\n",
    "        if use_bias:\n",
    "            nn.init.uniform_(self.linear.bias, -w_std, w_std)\n",
    "\n",
    "        self.activation = Sine(w0) if activation is None else activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        if self.is_last:\n",
    "            # We assume target data is in [0, 1], so adding 0.5 allows us to learn\n",
    "            # zero-centered features\n",
    "            out += 0\n",
    "        else:\n",
    "            out = self.activation(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Siren(nn.Module):\n",
    "    \"\"\"SIREN model.\n",
    "\n",
    "    Args:\n",
    "        dim_in (int): Dimension of input.\n",
    "        dim_hidden (int): Dimension of hidden layers.\n",
    "        dim_out (int): Dimension of output.\n",
    "        num_layers (int): Number of layers.\n",
    "        w0 (float): Omega 0 from SIREN paper.\n",
    "        w0_initial (float): Omega 0 for first layer.\n",
    "        use_bias (bool): Whether to learn bias in linear layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_in,\n",
    "        dim_hidden,\n",
    "        dim_out,\n",
    "        num_layers,\n",
    "        w0=30.0,\n",
    "        w0_initial=30.0,\n",
    "        use_bias=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.dim_out = dim_out\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        layers = []\n",
    "        for ind in range(num_layers - 1):\n",
    "            is_first = ind == 0\n",
    "            layer_w0 = w0_initial if is_first else w0\n",
    "            layer_dim_in = dim_in if is_first else dim_hidden\n",
    "\n",
    "            layers.append(\n",
    "                SirenLayer(\n",
    "                    dim_in=layer_dim_in,\n",
    "                    dim_out=dim_hidden,\n",
    "                    w0=layer_w0,\n",
    "                    use_bias=use_bias,\n",
    "                    is_first=is_first,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "        self.last_layer = SirenLayer(\n",
    "            dim_in=dim_hidden, dim_out=dim_out, w0=w0, use_bias=use_bias, is_last=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of SIREN model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Tensor of shape (*, dim_in), where * means any\n",
    "                number of dimensions.\n",
    "\n",
    "        Returns:\n",
    "            Tensor of shape (*, dim_out).\n",
    "        \"\"\"\n",
    "        x = self.net(x)\n",
    "        return self.last_layer(x)\n",
    "\n",
    "\n",
    "class ModulatedSiren(Siren):\n",
    "    \"\"\"Modulated SIREN model.\n",
    "\n",
    "    Args:\n",
    "        dim_in (int): Dimension of input.\n",
    "        dim_hidden (int): Dimension of hidden layers.\n",
    "        dim_out (int): Dimension of output.\n",
    "        num_layers (int): Number of layers.\n",
    "        w0 (float): Omega 0 from SIREN paper.\n",
    "        w0_initial (float): Omega 0 for first layer.\n",
    "        use_bias (bool): Whether to learn bias in linear layer.\n",
    "        modulate_scale (bool): Whether to modulate with scales.\n",
    "        modulate_shift (bool): Whether to modulate with shifts.\n",
    "        use_latent (bool): If true, use a latent vector which is mapped to\n",
    "            modulations, otherwise use modulations directly.\n",
    "        latent_dim (int): Dimension of latent vector.\n",
    "        modulation_net_dim_hidden (int): Number of hidden dimensions of\n",
    "            modulation network.\n",
    "        modulation_net_num_layers (int): Number of layers in modulation network.\n",
    "            If this is set to 1 will correspond to a linear layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_in,\n",
    "        dim_hidden,\n",
    "        dim_out,\n",
    "        num_layers,\n",
    "        w0=30.0,\n",
    "        w0_initial=30.0,\n",
    "        use_bias=True,\n",
    "        modulate_scale=False,\n",
    "        modulate_shift=True,\n",
    "        use_latent=False,\n",
    "        latent_dim=64,\n",
    "        modulation_net_dim_hidden=64,\n",
    "        modulation_net_num_layers=1,\n",
    "        mu=0,\n",
    "        sigma=1,\n",
    "        last_activation=None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            dim_in,\n",
    "            dim_hidden,\n",
    "            dim_out,\n",
    "            num_layers,\n",
    "            w0,\n",
    "            w0_initial,\n",
    "            use_bias,\n",
    "        )\n",
    "        # Must modulate at least one of scale and shift\n",
    "        assert modulate_scale or modulate_shift\n",
    "\n",
    "        self.modulate_scale = modulate_scale\n",
    "        self.modulate_shift = modulate_shift\n",
    "        self.w0 = w0\n",
    "        self.w0_initial = w0_initial\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.last_activation = (\n",
    "            nn.Identity() if last_activation is None else last_activation\n",
    "        )\n",
    "\n",
    "        # We modulate features at every *hidden* layer of the base network and\n",
    "        # therefore have dim_hidden * (num_layers - 1) modulations, since the\n",
    "        # last layer is not modulated\n",
    "        num_modulations = dim_hidden * (num_layers - 1)\n",
    "        if self.modulate_scale and self.modulate_shift:\n",
    "            # If we modulate both scale and shift, we have twice the number of\n",
    "            # modulations at every layer and feature\n",
    "            num_modulations *= 2\n",
    "\n",
    "        if use_latent:\n",
    "            self.modulation_net = LatentToModulation(\n",
    "                latent_dim,\n",
    "                num_modulations,\n",
    "                modulation_net_dim_hidden,\n",
    "                modulation_net_num_layers,\n",
    "            )\n",
    "        else:\n",
    "            self.modulation_net = Bias(num_modulations)\n",
    "\n",
    "        # Initialize scales to 1 and shifts to 0 (i.e. the identity)\n",
    "        if not use_latent:\n",
    "            if self.modulate_shift and self.modulate_scale:\n",
    "                self.modulation_net.bias.data = torch.cat(\n",
    "                    (\n",
    "                        torch.ones(num_modulations // 2),\n",
    "                        torch.zeros(num_modulations // 2),\n",
    "                    ),\n",
    "                    dim=0,\n",
    "                )\n",
    "            elif self.modulate_scale:\n",
    "                self.modulation_net.bias.data = torch.ones(num_modulations)\n",
    "            else:\n",
    "                self.modulation_net.bias.data = torch.zeros(num_modulations)\n",
    "\n",
    "        self.num_modulations = num_modulations\n",
    "\n",
    "    def modulated_forward(self, x, latent):\n",
    "        \"\"\"Forward pass of modulated SIREN model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Shape (batch_size, *, dim_in), where * refers to\n",
    "                any spatial dimensions, e.g. (height, width), (height * width,)\n",
    "                or (depth, height, width) etc.\n",
    "            latent (torch.Tensor): Shape (batch_size, latent_dim). If\n",
    "                use_latent=False, then latent_dim = num_modulations.\n",
    "\n",
    "        Returns:\n",
    "            Output features of shape (batch_size, *, dim_out).\n",
    "        \"\"\"\n",
    "        # Extract batch_size and spatial dims of x, so we can reshape output\n",
    "        x_shape = x.shape[:-1]\n",
    "        # Flatten all spatial dimensions, i.e. shape\n",
    "        # (batch_size, *, dim_in) -> (batch_size, num_points, dim_in)\n",
    "\n",
    "        x = x.view(x.shape[0], -1, x.shape[-1])\n",
    "\n",
    "        # Shape (batch_size, num_modulations)\n",
    "        modulations = self.modulation_net(latent)\n",
    "\n",
    "        # Split modulations into shifts and scales and apply them to hidden\n",
    "        # features.\n",
    "        mid_idx = (\n",
    "            self.num_modulations // 2\n",
    "            if (self.modulate_scale and self.modulate_shift)\n",
    "            else 0\n",
    "        )\n",
    "        idx = 0\n",
    "        for module in self.net:\n",
    "            if self.modulate_scale:\n",
    "                # Shape (batch_size, 1, dim_hidden). Note that we add 1 so\n",
    "                # modulations remain zero centered\n",
    "                scale = modulations[:, idx: idx +\n",
    "                                    self.dim_hidden].unsqueeze(1) + 1.0\n",
    "            else:\n",
    "                scale = 1.0\n",
    "\n",
    "            if self.modulate_shift:\n",
    "                # Shape (batch_size, 1, dim_hidden)\n",
    "                shift = modulations[\n",
    "                    :, mid_idx + idx: mid_idx + idx + self.dim_hidden\n",
    "                ].unsqueeze(1)\n",
    "            else:\n",
    "                shift = 0.0\n",
    "\n",
    "            x = module.linear(x)\n",
    "            x = scale * x + shift  # Broadcast scale and shift across num_points\n",
    "            x = module.activation(x)  # (batch_size, num_points, dim_hidden)\n",
    "\n",
    "            idx = idx + self.dim_hidden\n",
    "\n",
    "        # Shape (batch_size, num_points, dim_out)\n",
    "        out = self.last_activation(self.last_layer(x))\n",
    "        out = out * self.sigma + self.mu\n",
    "        # Reshape (batch_size, num_points, dim_out) -> (batch_size, *, dim_out)\n",
    "        return out.view(*x_shape, out.shape[-1])\n",
    "\n",
    "\n",
    "class LatentToModulation(nn.Module):\n",
    "    \"\"\"Maps a latent vector to a set of modulations.\n",
    "    Args:\n",
    "        latent_dim (int):\n",
    "        num_modulations (int):\n",
    "        dim_hidden (int):\n",
    "        num_layers (int):\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, latent_dim, num_modulations, dim_hidden, num_layers, activation=nn.SiLU\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_modulations = num_modulations\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.num_layers = num_layers\n",
    "        self.activation = activation\n",
    "\n",
    "        if num_layers == 1:\n",
    "            self.net = nn.Linear(latent_dim, num_modulations)\n",
    "        else:\n",
    "            layers = [nn.Linear(latent_dim, dim_hidden), self.activation()]\n",
    "            if num_layers > 2:\n",
    "                for i in range(num_layers - 2):\n",
    "                    layers += [nn.Linear(dim_hidden, dim_hidden),\n",
    "                               self.activation()]\n",
    "            layers += [nn.Linear(dim_hidden, num_modulations)]\n",
    "            self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, latent):\n",
    "        return self.net(latent)\n",
    "\n",
    "\n",
    "class Bias(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super().__init__()\n",
    "        self.bias = nn.Parameter(torch.zeros(size), requires_grad=True)\n",
    "        # Add latent_dim attribute for compatibility with LatentToModulation model\n",
    "        self.latent_dim = size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.bias\n",
    "\n",
    "\n",
    "class ConvLatentToModulation(nn.Module):\n",
    "    \"\"\"Maps a latent vector to a set of modulations.\n",
    "\n",
    "    Args:\n",
    "        latent_dim (int):\n",
    "        num_modulations (int):\n",
    "        dim_hidden (int):\n",
    "        num_layers (int):\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, input_dim, grid_size, latent_dim, num_modulations, kernel_size=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_modulations = num_modulations\n",
    "        self.grid_size = grid_size\n",
    "\n",
    "        if input_dim == 2:\n",
    "            self.net = nn.Conv2d(latent_dim, num_modulations, kernel_size)\n",
    "        elif input_dim == 1:\n",
    "            self.net = nn.Conv1d(latent_dim, num_modulations, kernel_size)\n",
    "            # self.coords = shape2coordinates([grid_size, grid_size])\n",
    "\n",
    "    def forward(self, latent):\n",
    "        return self.net(latent)\n",
    "\n",
    "\n",
    "class ConvModulatedSiren(Siren):\n",
    "    \"\"\"Modulated SIREN model.\n",
    "\n",
    "    Args:\n",
    "        dim_in (int): Dimension of input.\n",
    "        dim_hidden (int): Dimension of hidden layers.\n",
    "        dim_out (int): Dimension of output.\n",
    "        num_layers (int): Number of layers.\n",
    "        w0 (float): Omega 0 from SIREN paper.\n",
    "        w0_initial (float): Omega 0 for first layer.\n",
    "        use_bias (bool): Whether to learn bias in linear layer.\n",
    "        modulate_scale (bool): Whether to modulate with scales.\n",
    "        modulate_shift (bool): Whether to modulate with shifts.\n",
    "        use_latent (bool): If true, use a latent vector which is mapped to\n",
    "            modulations, otherwise use modulations directly.\n",
    "        latent_dim (int): Dimension of latent vector.\n",
    "        modulation_net_dim_hidden (int): Number of hidden dimensions of\n",
    "            modulation network.\n",
    "        modulation_net_num_layers (int): Number of layers in modulation network.\n",
    "            If this is set to 1 will correspond to a linear layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_in,\n",
    "        dim_hidden,\n",
    "        dim_out,\n",
    "        num_layers,\n",
    "        w0=30.0,\n",
    "        w0_initial=30.0,\n",
    "        use_bias=True,\n",
    "        modulate_scale=False,\n",
    "        modulate_shift=True,\n",
    "        use_latent=False,\n",
    "        latent_dim=64,\n",
    "        mu=0,\n",
    "        sigma=1,\n",
    "        last_activation=None,\n",
    "        grid_size=8,\n",
    "        interpolation=\"bilinear\",\n",
    "        conv_kernel=3,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            dim_in,\n",
    "            dim_hidden,\n",
    "            dim_out,\n",
    "            num_layers,\n",
    "            w0,\n",
    "            w0_initial,\n",
    "            use_bias,\n",
    "        )\n",
    "        # Must modulate at least one of scale and shift\n",
    "        assert modulate_scale or modulate_shift\n",
    "\n",
    "        self.modulate_scale = modulate_scale\n",
    "        self.modulate_shift = modulate_shift\n",
    "        self.w0 = w0\n",
    "        self.w0_initial = w0_initial\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.grid_size = grid_size\n",
    "        self.interpolation = interpolation\n",
    "        self.last_activation = (\n",
    "            nn.Identity() if last_activation is None else last_activation\n",
    "        )\n",
    "\n",
    "        # We modulate features at every *hidden* layer of the base network and\n",
    "        # therefore have dim_hidden * (num_layers - 1) modulations, since the\n",
    "        # last layer is not modulated\n",
    "        num_modulations = dim_hidden * (num_layers - 1)\n",
    "        if self.modulate_scale and self.modulate_shift:\n",
    "            # If we modulate both scale and shift, we have twice the number of\n",
    "            # modulations at every layer and feature\n",
    "            num_modulations *= 2\n",
    "\n",
    "        self.modulation_net = ConvLatentToModulation(\n",
    "            dim_in, grid_size, latent_dim, num_modulations, conv_kernel\n",
    "        )\n",
    "\n",
    "        # Initialize scales to 1 and shifts to 0 (i.e. the identity)\n",
    "        if not use_latent:\n",
    "            if self.modulate_shift and self.modulate_scale:\n",
    "                self.modulation_net.bias.data = torch.cat(\n",
    "                    (\n",
    "                        torch.ones(num_modulations // 2),\n",
    "                        torch.zeros(num_modulations // 2),\n",
    "                    ),\n",
    "                    dim=0,\n",
    "                )\n",
    "            elif self.modulate_scale:\n",
    "                self.modulation_net.bias.data = torch.ones(num_modulations)\n",
    "            else:\n",
    "                self.modulation_net.bias.data = torch.zeros(num_modulations)\n",
    "\n",
    "        self.num_modulations = num_modulations\n",
    "\n",
    "        # self.mode = \"linear\" if dim_in == 1 else \"bilinear\"\n",
    "\n",
    "    def modulated_forward(self, x, latent):\n",
    "        \"\"\"Forward pass of modulated SIREN model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Shape (batch_size, *, dim_in), where * refers to\n",
    "                any spatial dimensions, e.g. (height, width), (height * width,)\n",
    "                or (depth, height, width) etc.\n",
    "            latent (torch.Tensor): Shape (batch_size, latent_dim). If\n",
    "                use_latent=False, then latent_dim = num_modulations.\n",
    "\n",
    "        Returns:\n",
    "            Output features of shape (batch_size, *, dim_out).\n",
    "        \"\"\"\n",
    "        # Extract batch_size and spatial dims of x, so we can reshape output\n",
    "        x_shape = x.shape[:-1]\n",
    "        # Flatten all spatial dimensions, i.e. shape\n",
    "        # (batch_size, *, dim_in) -> (batch_size, num_points, dim_in)\n",
    "\n",
    "        # Shape (batch_size, num_modulations)\n",
    "        modulations = self.modulation_net(latent)\n",
    "        # print('mod1', modulations.shape)\n",
    "        # v1 modulations = torch.nn.functional.grid_sample(modulations, x, mode='bilinear', padding_mode='zeros', align_corners=None)\n",
    "        # v2 modulations = grid_sample(modulations, x)\n",
    "        # vtest\n",
    "        modulations = torch.nn.functional.interpolate(\n",
    "            modulations, x.shape[1:-1], mode=self.interpolation\n",
    "        )\n",
    "        # print('mod2', modulations.shape)\n",
    "\n",
    "        x = x.view(x.shape[0], -1, x.shape[-1])\n",
    "        # modulations = modulations.permute(0, 2, 3, 1)\n",
    "\n",
    "        # place the channel at the end\n",
    "        modulations = torch.movedim(modulations, 1, -1)\n",
    "        modulations = modulations.view(x.shape[0], -1, self.num_modulations)\n",
    "        # print('mod', modulations.shape)\n",
    "\n",
    "        # Split modulations into shifts and scales and apply them to hidden\n",
    "        # features.\n",
    "        mid_idx = (\n",
    "            self.num_modulations // 2\n",
    "            if (self.modulate_scale and self.modulate_shift)\n",
    "            else 0\n",
    "        )\n",
    "        idx = 0\n",
    "        for module in self.net:\n",
    "            if self.modulate_scale:\n",
    "                # Shape (batch_size, 1, dim_hidden). Note that we add 1 so\n",
    "                # modulations remain zero centered\n",
    "                scale = modulations[:, :, idx: idx + self.dim_hidden] + 1.0\n",
    "            else:\n",
    "                scale = 1.0\n",
    "\n",
    "            if self.modulate_shift:\n",
    "                # Shape (batch_size, 1, dim_hidden)\n",
    "                shift = modulations[\n",
    "                    :, :, mid_idx + idx: mid_idx + idx + self.dim_hidden\n",
    "                ]\n",
    "            else:\n",
    "                shift = 0.0\n",
    "\n",
    "            x = module.linear(x)\n",
    "            x = scale * x + shift  # Broadcast scale and shift across num_points\n",
    "            x = module.activation(x)  # (batch_size, num_points, dim_hidden)\n",
    "\n",
    "            idx = idx + self.dim_hidden\n",
    "\n",
    "        # Shape (batch_size, num_points, dim_out)\n",
    "        out = self.last_activation(self.last_layer(x))\n",
    "        # print('out', out.shape)\n",
    "        # Reshape (batch_size, num_points, dim_out) -> (batch_size, *, dim_out)\n",
    "        return out.view(*x_shape, out.shape[-1])\n",
    "\n",
    "\n",
    "class ConvModulatedSiren2(Siren):\n",
    "    \"\"\"Modulated SIREN model.\n",
    "\n",
    "    Args:\n",
    "        dim_in (int): Dimension of input.\n",
    "        dim_hidden (int): Dimension of hidden layers.\n",
    "        dim_out (int): Dimension of output.\n",
    "        num_layers (int): Number of layers.\n",
    "        w0 (float): Omega 0 from SIREN paper.\n",
    "        w0_initial (float): Omega 0 for first layer.\n",
    "        use_bias (bool): Whether to learn bias in linear layer.\n",
    "        modulate_scale (bool): Whether to modulate with scales.\n",
    "        modulate_shift (bool): Whether to modulate with shifts.\n",
    "        use_latent (bool): If true, use a latent vector which is mapped to\n",
    "            modulations, otherwise use modulations directly.\n",
    "        latent_dim (int): Dimension of latent vector.\n",
    "        modulation_net_dim_hidden (int): Number of hidden dimensions of\n",
    "            modulation network.\n",
    "        modulation_net_num_layers (int): Number of layers in modulation network.\n",
    "            If this is set to 1 will correspond to a linear layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_in,\n",
    "        dim_hidden,\n",
    "        dim_out,\n",
    "        num_layers,\n",
    "        w0=30.0,\n",
    "        w0_initial=30.0,\n",
    "        use_bias=True,\n",
    "        modulate_scale=False,\n",
    "        modulate_shift=True,\n",
    "        use_latent=False,\n",
    "        latent_dim=64,\n",
    "        mu=0,\n",
    "        sigma=1,\n",
    "        last_activation=None,\n",
    "        grid_size=8,\n",
    "        interpolation=\"bilinear\",\n",
    "        conv_kernel=3,\n",
    "        rescale_coordinate=False,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            dim_in,\n",
    "            dim_hidden,\n",
    "            dim_out,\n",
    "            num_layers,\n",
    "            w0,\n",
    "            w0_initial,\n",
    "            use_bias,\n",
    "        )\n",
    "        # Must modulate at least one of scale and shift\n",
    "        assert modulate_scale or modulate_shift\n",
    "\n",
    "        self.modulate_scale = modulate_scale\n",
    "        self.modulate_shift = modulate_shift\n",
    "        self.w0 = w0\n",
    "        self.w0_initial = w0_initial\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.grid_size = grid_size\n",
    "        self.interpolation = interpolation\n",
    "        self.last_activation = (\n",
    "            nn.Identity() if last_activation is None else last_activation\n",
    "        )\n",
    "        self.rescale_coordinate = rescale_coordinate\n",
    "\n",
    "        # We modulate features at every *hidden* layer of the base network and\n",
    "        # therefore have dim_hidden * (num_layers - 1) modulations, since the\n",
    "        # last layer is not modulated\n",
    "        num_modulations = dim_hidden * (num_layers - 1)\n",
    "        if self.modulate_scale and self.modulate_shift:\n",
    "            # If we modulate both scale and shift, we have twice the number of\n",
    "            # modulations at every layer and feature\n",
    "            num_modulations *= 2\n",
    "\n",
    "        self.modulation_net = ConvLatentToModulation(\n",
    "            dim_in, grid_size, latent_dim, num_modulations, conv_kernel\n",
    "        )\n",
    "\n",
    "        # Initialize scales to 1 and shifts to 0 (i.e. the identity)\n",
    "        if not use_latent:\n",
    "            if self.modulate_shift and self.modulate_scale:\n",
    "                self.modulation_net.bias.data = torch.cat(\n",
    "                    (\n",
    "                        torch.ones(num_modulations // 2),\n",
    "                        torch.zeros(num_modulations // 2),\n",
    "                    ),\n",
    "                    dim=0,\n",
    "                )\n",
    "            elif self.modulate_scale:\n",
    "                self.modulation_net.bias.data = torch.ones(num_modulations)\n",
    "            else:\n",
    "                self.modulation_net.bias.data = torch.zeros(num_modulations)\n",
    "\n",
    "        self.num_modulations = num_modulations\n",
    "\n",
    "        # create modulation positions\n",
    "        crds = []\n",
    "        for i in range(dim_in):\n",
    "            crds.append(torch.linspace(0.0, 1.0, grid_size))\n",
    "        self.modulation_grid = torch.stack(\n",
    "            torch.meshgrid(*crds, indexing=\"ij\"), dim=-1)\n",
    "\n",
    "    def modulated_forward(self, x, latent):\n",
    "        \"\"\"Forward pass of modulated SIREN model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Shape (batch_size, *, dim_in), where * refers to\n",
    "                any spatial dimensions, e.g. (height, width), (height * width,)\n",
    "                or (depth, height, width) etc.\n",
    "            latent (torch.Tensor): Shape (batch_size, latent_dim). If\n",
    "                use_latent=False, then latent_dim = num_modulations.\n",
    "\n",
    "        Returns:\n",
    "            Output features of shape (batch_size, *, dim_out).\n",
    "        \"\"\"\n",
    "        # Extract batch_size and spatial dims of x, so we can reshape output\n",
    "        x_shape = x.shape[:-1]\n",
    "        x = x.view(x.shape[0], -1, x.shape[-1])\n",
    "        batch_size, num_points = x.shape[0], x.shape[1]\n",
    "        # Flatten all spatial dimensions, i.e. shape\n",
    "        # (batch_size, *, dim_in) -> (batch_size, num_points, dim_in)\n",
    "\n",
    "        # Shape (batch_size, num_modulations)\n",
    "        modulations = self.modulation_net(latent)\n",
    "\n",
    "        # print('toto', modulations.shape, latent.shape)\n",
    "        modulations = torch.movedim(modulations, 1, -1)\n",
    "\n",
    "        modulations = modulations.view(\n",
    "            modulations.shape[0], -1, modulations.shape[-1])\n",
    "\n",
    "        mod_grid = self.modulation_grid.view(-1, x.shape[-1])\n",
    "        mod_grid = (\n",
    "            mod_grid.unsqueeze(0)\n",
    "            .repeat(x_shape[0], *(1,) * self.modulation_grid.ndim)\n",
    "            .cuda()\n",
    "        )\n",
    "\n",
    "        x_batch = (\n",
    "            torch.arange(modulations.shape[0])\n",
    "            .view(-1, 1)\n",
    "            .repeat(1, modulations.shape[1])\n",
    "            .flatten()\n",
    "            .cuda()\n",
    "        )\n",
    "        y_batch = (\n",
    "            torch.arange(x.shape[0]).view(-1, 1).repeat(1,\n",
    "                                                        x.shape[1]).flatten().cuda()\n",
    "        )\n",
    "\n",
    "        # print('tototot')\n",
    "        # print(einops.rearrange(modulations, 'b d c -> (b d) c').shape,\n",
    "        #      einops.rearrange(mod_grid, 'b d c -> (b d) c').shape,\n",
    "        #      x.view(-1, x.shape[-1]).shape,\n",
    "        #      x_batch.shape,\n",
    "        #      y_batch.shape)\n",
    "\n",
    "        modulations = knn_interpolate_custom(\n",
    "            einops.rearrange(modulations, \"b d c -> (b d) c\"),\n",
    "            einops.rearrange(mod_grid, \"b d c -> (b d) c\"),\n",
    "            x.view(-1, x.shape[-1]),\n",
    "            batch_x=x_batch,\n",
    "            batch_y=y_batch,\n",
    "        )\n",
    "        if self.rescale_coordinate:\n",
    "            x = rescale_coordinate(\n",
    "                self.modulation_grid.cuda(), x.view(-1, x.shape[-1]))\n",
    "\n",
    "        x = x.view(batch_size, -1, x.shape[-1])\n",
    "        modulations = modulations.view(batch_size, -1, modulations.shape[-1])\n",
    "\n",
    "        # Split modulations into shifts and scales and apply them to hidden\n",
    "        # features.\n",
    "        mid_idx = (\n",
    "            self.num_modulations // 2\n",
    "            if (self.modulate_scale and self.modulate_shift)\n",
    "            else 0\n",
    "        )\n",
    "        idx = 0\n",
    "        for module in self.net:\n",
    "            if self.modulate_scale:\n",
    "                # Shape (batch_size, 1, dim_hidden). Note that we add 1 so\n",
    "                # modulations remain zero centered\n",
    "                scale = modulations[:, :, idx: idx + self.dim_hidden] + 1.0\n",
    "            else:\n",
    "                scale = 1.0\n",
    "\n",
    "            if self.modulate_shift:\n",
    "                # Shape (batch_size, 1, dim_hidden)\n",
    "                shift = modulations[\n",
    "                    :, :, mid_idx + idx: mid_idx + idx + self.dim_hidden\n",
    "                ]\n",
    "            else:\n",
    "                shift = 0.0\n",
    "\n",
    "            x = module.linear(x)\n",
    "            x = scale * x + shift  # Broadcast scale and shift across num_points\n",
    "            x = module.activation(x)  # (batch_size, num_points, dim_hidden)\n",
    "\n",
    "            idx = idx + self.dim_hidden\n",
    "\n",
    "        # Shape (batch_size, num_points, dim_out)\n",
    "        out = self.last_activation(self.last_layer(x))\n",
    "        # print('out', out.shape)\n",
    "        # Reshape (batch_size, num_points, dim_out) -> (batch_size, *, dim_out)\n",
    "        return out.view(*x_shape, out.shape[-1])\n",
    "\n",
    "\n",
    "class SSN(nn.Module):\n",
    "    \"\"\"Simple Sine model.\n",
    "\n",
    "    Args:\n",
    "        dim_in (int): Dimension of input.\n",
    "        dim_hidden (int): Dimension of hidden layers.\n",
    "        dim_out (int): Dimension of output.\n",
    "        num_layers (int): Number of layers.\n",
    "        w0 (float): Omega 0 from SIREN paper.\n",
    "        w0_initial (float): Omega 0 for first layer.\n",
    "        use_bias (bool): Whether to learn bias in linear layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_in,\n",
    "        dim_hidden,\n",
    "        dim_out,\n",
    "        num_layers,\n",
    "        w0=30.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.dim_out = dim_out\n",
    "        self.num_layers = num_layers\n",
    "        self.w0 = w0\n",
    "\n",
    "        layers = [nn.Linear(dim_in, dim_hidden)]\n",
    "        for j in range(self.num_layers-1):\n",
    "            layers.append(nn.Linear(dim_hidden, dim_hidden))\n",
    "        layers.append(nn.Linear(dim_hidden, dim_out))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "        self.init_weights()\n",
    "                          \n",
    "    def init_weights(self):\n",
    "        for j, layer in enumerate(self.layers):\n",
    "            if j == 0:\n",
    "                nn.init.normal(layer.weight, 0,  np.sqrt(2) / np.sqrt(layer.weight.shape[1]))\n",
    "                #nn.init.uniform(layer.weight, -self.w0 / layer.weight.shape[1], self.w0 / layer.weight.shape[1])\n",
    "            else:\n",
    "                nn.init.normal(layer.weight, 0, np.sqrt(2) / np.sqrt(layer.weight.shape[1]))\n",
    "            print(layer.weight.std())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for j, layer in enumerate(self.layers[:-1]):\n",
    "            if j == 0:\n",
    "                x = torch.sin(self.w0*layer(x))\n",
    "            else:\n",
    "                x = torch.sin(layer(x))\n",
    "        out = self.layers[-1](x)\n",
    "        return out \n",
    "\n",
    "\n",
    "\n",
    "class ModulatedSSN(nn.Module):\n",
    "    \"\"\"Modulated Sine model.\n",
    "\n",
    "    Args:\n",
    "        dim_in (int): Dimension of input.\n",
    "        dim_hidden (int): Dimension of hidden layers.\n",
    "        dim_out (int): Dimension of output.\n",
    "        num_layers (int): Number of layers.\n",
    "        w0 (float): Omega 0 from SIREN paper.\n",
    "        w0_initial (float): Omega 0 for first layer.\n",
    "        use_bias (bool): Whether to learn bias in linear layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_in,\n",
    "        dim_hidden,\n",
    "        dim_out,\n",
    "        num_layers,\n",
    "        w0=30.0,\n",
    "        latent_dim=64,\n",
    "        modulation_net_dim_hidden=64,\n",
    "        modulation_net_num_layers=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.dim_out = dim_out\n",
    "        self.num_layers = num_layers\n",
    "        self.w0 = w0\n",
    "        self.latent_dim = latent_dim    \n",
    "\n",
    "        layers = [nn.Linear(dim_in, dim_hidden)]\n",
    "        for j in range(self.num_layers-1):\n",
    "            layers.append(nn.Linear(dim_hidden, dim_hidden))\n",
    "        layers.append(nn.Linear(dim_hidden, dim_out))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.num_modulations = dim_hidden * len(self.layers[:-1])    \n",
    "\n",
    "        self.modulation_net = LatentToModulation(\n",
    "                latent_dim,\n",
    "                self.num_modulations,\n",
    "                modulation_net_dim_hidden,\n",
    "                modulation_net_num_layers,\n",
    "            )\n",
    "        self.init_weights()\n",
    "                          \n",
    "    def init_weights(self):\n",
    "        for j, layer in enumerate(self.layers):\n",
    "            if j == 0:\n",
    "                nn.init.normal(layer.weight, 0,  np.sqrt(2) / np.sqrt(layer.weight.shape[1]))\n",
    "                #nn.init.uniform(layer.weight, -self.w0 / layer.weight.shape[1], self.w0 / layer.weight.shape[1])\n",
    "            else:\n",
    "                nn.init.normal(layer.weight, 0, np.sqrt(2) / np.sqrt(layer.weight.shape[1]))\n",
    "            print(layer.weight.std())\n",
    "        \n",
    "    def modulated_forward(self, x, z):\n",
    "        x_shape = x.shape[:-1]\n",
    "        x = x.view(x.shape[0], -1, x.shape[-1])\n",
    "        modulations = self.modulation_net(z)\n",
    "        modulations = modulations.reshape(-1, self.latent_dim, len(self.layers[:-1])).unsqueeze(1)\n",
    "\n",
    "        for j, layer in enumerate(self.layers[:-1]):\n",
    "            if j == 0:\n",
    "                x = torch.sin(self.w0*layer(x) + modulations[..., j])\n",
    "            else:\n",
    "                x = torch.sin(layer(x) + modulations[..., j])\n",
    "        out = self.layers[-1](x)\n",
    "\n",
    "        return out.view(*x_shape, out.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56db762",
   "metadata": {},
   "source": [
    "# GPT implementation of encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50430376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class FunctionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset to handle sampled input functions.\n",
    "    Args:\n",
    "        samples (torch.Tensor): Input coordinates of shape (num_samples, dim_in).\n",
    "        values (torch.Tensor): Corresponding function values of shape (num_samples, dim_out).\n",
    "    \"\"\"\n",
    "    def __init__(self, samples, values):\n",
    "        super().__init__()\n",
    "        self.samples = samples\n",
    "        self.values = values\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx], self.values[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e0e2093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_sample = data_train[0][0]\n",
    "\n",
    "samples = []\n",
    "values = []\n",
    "\n",
    "for i in range(u_sample.shape[0]):\n",
    "    for j in range(u_sample.shape[1]):\n",
    "        samples.append(coord_grid[i, j])\n",
    "        values.append(u_sample[i, j])\n",
    "        \n",
    "samples_tensor = torch.tensor(samples, dtype=torch.float)\n",
    "values_tensor = torch.tensor(values, dtype=torch.float).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3c7e378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4356, 2]), torch.Size([4356, 1]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_tensor.shape, values_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2fb1c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Hyper-network that maps a latent code to modulation parameters.\n",
    "    Args:\n",
    "        latent_dim (int): Dimension of the latent code.\n",
    "        num_modulations (int): Number of modulation parameters.\n",
    "        hidden_dim (int): Dimension of hidden layers in the hyper-network.\n",
    "        num_layers (int): Number of layers in the hyper-network.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim, num_modulations, hidden_dim, num_layers):\n",
    "        super().__init__()\n",
    "        layers = [nn.Linear(latent_dim, hidden_dim), nn.ReLU()]\n",
    "        for _ in range(num_layers - 2):\n",
    "            layers += [nn.Linear(hidden_dim, hidden_dim), nn.ReLU()]\n",
    "        layers.append(nn.Linear(hidden_dim, num_modulations))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "\n",
    "class CORALEncoderHyper(nn.Module):\n",
    "    \"\"\"\n",
    "    CORAL Encoder with hyper-network for auto-decoding.\n",
    "    Args:\n",
    "        input_dim (int): Dimension of the input space.\n",
    "        hidden_dim (int): Dimension of hidden layers in the SIREN.\n",
    "        latent_dim (int): Dimension of the latent code.\n",
    "        output_dim (int): Dimension of the output space (function values).\n",
    "        num_layers (int): Number of SIREN layers.\n",
    "        w0 (float): Omega_0 value for sine activation.\n",
    "        lr (float): Learning rate for optimization.\n",
    "        hyper_hidden_dim (int): Hidden dimension in the hyper-network.\n",
    "        hyper_layers (int): Number of layers in the hyper-network.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, output_dim, num_layers, w0=30.0, lr=1e-3,\n",
    "                 hyper_hidden_dim=64, hyper_layers=3):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.siren = Siren(\n",
    "            dim_in=input_dim,\n",
    "            dim_hidden=hidden_dim,\n",
    "            dim_out=output_dim,\n",
    "            num_layers=num_layers,\n",
    "            w0=w0\n",
    "        )\n",
    "        self.hyper_net = HyperNetwork(\n",
    "            latent_dim=latent_dim,\n",
    "            num_modulations=hidden_dim * (num_layers - 1),  # Number of modulations for hidden layers\n",
    "            hidden_dim=hyper_hidden_dim,\n",
    "            num_layers=hyper_layers\n",
    "        )\n",
    "        self.latent_code = nn.Parameter(torch.zeros(latent_dim), requires_grad=True)\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the INR modulated by parameters from the hyper-network.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input coordinates of shape (batch_size, input_dim).\n",
    "        Returns:\n",
    "            torch.Tensor: Reconstructed function values of shape (batch_size, output_dim).\n",
    "        \"\"\"\n",
    "        modulations = self.hyper_net(self.latent_code)\n",
    "        return self.siren_with_modulation(x, modulations)\n",
    "\n",
    "    def siren_with_modulation(self, x, modulations):\n",
    "        \"\"\"\n",
    "        Modulate the SIREN with the hyper-network's output.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input coordinates.\n",
    "            modulations (torch.Tensor): Modulation parameters from the hyper-network.\n",
    "        Returns:\n",
    "            torch.Tensor: Output of the SIREN.\n",
    "        \"\"\"\n",
    "        idx = 0\n",
    "        for layer in self.siren.net:\n",
    "            x = layer.linear(x)\n",
    "            x = x * modulations[idx: idx + layer.dim_out] + 1.0  # Scale modulation\n",
    "            x = layer.activation(x)\n",
    "            idx += layer.dim_out\n",
    "        return self.siren.last_layer(x)\n",
    "\n",
    "    def encode(self, dataset, num_epochs=500, batch_size=128):\n",
    "        \"\"\"\n",
    "        Optimize the latent code to encode the input function.\n",
    "        Args:\n",
    "            dataset (Dataset): Dataset containing input coordinates and function values.\n",
    "            num_epochs (int): Number of optimization steps.\n",
    "            batch_size (int): Batch size for training.\n",
    "        Returns:\n",
    "            torch.Tensor: Optimized latent code representing the input function.\n",
    "        \"\"\"\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        optimizer = optim.Adam([self.latent_code], lr=self.lr)\n",
    "        loss_fn = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss = 0\n",
    "            for coords, values in dataloader:\n",
    "                optimizer.zero_grad()\n",
    "                preds = self.forward(coords)\n",
    "                loss = loss_fn(preds, values)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            if (epoch + 1) % 50 == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "        return self.latent_code.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "88eabfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500, Loss: 631.8710\n",
      "Epoch 100/500, Loss: 667.1519\n",
      "Epoch 150/500, Loss: 630.5511\n",
      "Epoch 200/500, Loss: 629.5670\n",
      "Epoch 250/500, Loss: 630.9309\n",
      "Epoch 300/500, Loss: 626.2505\n",
      "Epoch 350/500, Loss: 628.1308\n",
      "Epoch 400/500, Loss: 625.9124\n",
      "Epoch 450/500, Loss: 625.8239\n",
      "Epoch 500/500, Loss: 631.9530\n",
      "Optimized Latent Code: tensor([  7.9867,   6.7610,  -6.0202,   3.7552,  -9.0773,   3.3845,   2.6099,\n",
      "         -0.0196,   7.4714,   0.3657,   2.3088,   9.7401,   6.3893,   7.2908,\n",
      "          4.9538,  -1.6567,  -4.6801,  -6.8735,   6.2920,   4.6968,  -3.1676,\n",
      "          7.4630,   4.2138,  -4.1387,  -0.4714,  -4.6254, -11.6401,  -1.9965,\n",
      "          4.1924,  -0.9238,   2.9957,  -2.4327])\n"
     ]
    }
   ],
   "source": [
    "# Define input function (e.g., a simple 2D sine wave)\n",
    "#coords = torch.rand(1000, 2)  # Input coordinates in [0, 1]^2\n",
    "#values = torch.sin(2 * torch.pi * coords[:, 0]) * torch.cos(2 * torch.pi * coords[:, 1])  # Function values\n",
    "#values = values.unsqueeze(-1)  # Reshape to (num_samples, output_dim)\n",
    "\n",
    "# Create dataset\n",
    "dataset = FunctionDataset(samples_tensor, values_tensor)\n",
    "\n",
    "# Initialize CORAL encoder with hyper-network\n",
    "coral_encoder = CORALEncoderHyper(\n",
    "    input_dim=2, hidden_dim=64, latent_dim=32, output_dim=1, num_layers=4, w0=30.0, lr=1e-3\n",
    ")\n",
    "\n",
    "# Optimize latent code\n",
    "latent_code = coral_encoder.encode(dataset)\n",
    "\n",
    "# Print the learned latent code\n",
    "print(\"Optimized Latent Code:\", latent_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d29b806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4356, 2]), torch.Size([4356, 1]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_tensor.shape, values_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "063052d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 2]), torch.Size([1000, 1]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords.shape, values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "145d3c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CORALTrainer:\n",
    "    def __init__(self, model, latent_dim, learning_rate=1e-3, lambda_=1e-2):\n",
    "        \"\"\"\n",
    "        Initialize the CORAL Trainer.\n",
    "        Args:\n",
    "            model (ModulatedSSN): The shared INR model.\n",
    "            latent_dim (int): Dimension of the latent code.\n",
    "            learning_rate (float): Learning rate for outer loop updates.\n",
    "            lambda_ (float): Scaling factor for outer updates.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.latent_dim = latent_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lambda_ = lambda_\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def train(self, dataset, num_epochs=100, batch_size=16, inner_steps=5, inner_lr=1e-2):\n",
    "        \"\"\"\n",
    "        Train the model following Algorithm 1.\n",
    "        Args:\n",
    "            dataset (Dataset): Dataset containing input functions.\n",
    "            num_epochs (int): Number of training epochs.\n",
    "            batch_size (int): Number of functions per batch.\n",
    "            inner_steps (int): Number of inner-loop optimization steps.\n",
    "            inner_lr (float): Learning rate for the inner loop.\n",
    "        \"\"\"\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        loss_fn = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for batch in dataloader:\n",
    "                coords, values = batch\n",
    "\n",
    "                # Initialize latent codes for all functions in the batch\n",
    "                batch_latent_codes = torch.zeros(len(values), self.latent_dim, requires_grad=True)\n",
    "                inner_optimizer = optim.SGD([batch_latent_codes], lr=inner_lr)\n",
    "\n",
    "                # Inner Encoding Loop: Optimize latent codes\n",
    "                for _ in range(inner_steps):\n",
    "                    inner_optimizer.zero_grad()\n",
    "                    total_loss = 0\n",
    "                    for i, (coord, value) in enumerate(zip(coords, values)):\n",
    "                        # Predict function values using the INR and latent code\n",
    "                        pred = self.model.modulated_forward(coord, batch_latent_codes[i])\n",
    "                        loss = loss_fn(pred, value)\n",
    "                        loss.backward()\n",
    "                        total_loss += loss.item()\n",
    "                    inner_optimizer.step()\n",
    "\n",
    "                # Outer Loop: Update shared parameters\n",
    "                self.optimizer.zero_grad()\n",
    "                batch_loss = 0\n",
    "                for i, (coord, value) in enumerate(zip(coords, values)):\n",
    "                    pred = self.model.modulated_forward(coord, batch_latent_codes[i])\n",
    "                    loss = loss_fn(pred, value)\n",
    "                    batch_loss += loss\n",
    "                batch_loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {batch_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0707ff4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prane\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([50])) that is different to the input size (torch.Size([50, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 2.9854\n",
      "Epoch 2/100, Loss: 4.2023\n",
      "Epoch 3/100, Loss: 4.7112\n",
      "Epoch 4/100, Loss: 3.9826\n",
      "Epoch 5/100, Loss: 2.8686\n",
      "Epoch 6/100, Loss: 1.7769\n",
      "Epoch 7/100, Loss: 2.2375\n",
      "Epoch 8/100, Loss: 3.6624\n",
      "Epoch 9/100, Loss: 4.1444\n",
      "Epoch 10/100, Loss: 4.4604\n",
      "Epoch 11/100, Loss: 4.4054\n",
      "Epoch 12/100, Loss: 4.0973\n",
      "Epoch 13/100, Loss: 4.6462\n",
      "Epoch 14/100, Loss: 4.4411\n",
      "Epoch 15/100, Loss: 4.2909\n",
      "Epoch 16/100, Loss: 1.4430\n",
      "Epoch 17/100, Loss: 5.3307\n",
      "Epoch 18/100, Loss: 2.2648\n",
      "Epoch 19/100, Loss: 5.7765\n",
      "Epoch 20/100, Loss: 4.2309\n",
      "Epoch 21/100, Loss: 6.2891\n",
      "Epoch 22/100, Loss: 3.7459\n",
      "Epoch 23/100, Loss: 3.9010\n",
      "Epoch 24/100, Loss: 2.9079\n",
      "Epoch 25/100, Loss: 1.5306\n",
      "Epoch 26/100, Loss: 3.1234\n",
      "Epoch 27/100, Loss: 2.7318\n",
      "Epoch 28/100, Loss: 6.1208\n",
      "Epoch 29/100, Loss: 3.7955\n",
      "Epoch 30/100, Loss: 5.9055\n",
      "Epoch 31/100, Loss: 3.2382\n",
      "Epoch 32/100, Loss: 3.8503\n",
      "Epoch 33/100, Loss: 3.1335\n",
      "Epoch 34/100, Loss: 3.3741\n",
      "Epoch 35/100, Loss: 3.2778\n",
      "Epoch 36/100, Loss: 3.5445\n",
      "Epoch 37/100, Loss: 3.5104\n",
      "Epoch 38/100, Loss: 5.3029\n",
      "Epoch 39/100, Loss: 2.6010\n",
      "Epoch 40/100, Loss: 2.4320\n",
      "Epoch 41/100, Loss: 3.5308\n",
      "Epoch 42/100, Loss: 3.8847\n",
      "Epoch 43/100, Loss: 2.7294\n",
      "Epoch 44/100, Loss: 4.9348\n",
      "Epoch 45/100, Loss: 3.9926\n",
      "Epoch 46/100, Loss: 5.4832\n",
      "Epoch 47/100, Loss: 2.7994\n",
      "Epoch 48/100, Loss: 2.4459\n",
      "Epoch 49/100, Loss: 3.4321\n",
      "Epoch 50/100, Loss: 5.9915\n",
      "Epoch 51/100, Loss: 4.1952\n",
      "Epoch 52/100, Loss: 3.5090\n",
      "Epoch 53/100, Loss: 5.6217\n",
      "Epoch 54/100, Loss: 3.3862\n",
      "Epoch 55/100, Loss: 3.3838\n",
      "Epoch 56/100, Loss: 2.1998\n",
      "Epoch 57/100, Loss: 3.8936\n",
      "Epoch 58/100, Loss: 3.6899\n",
      "Epoch 59/100, Loss: 3.0224\n",
      "Epoch 60/100, Loss: 2.8636\n",
      "Epoch 61/100, Loss: 4.8577\n",
      "Epoch 62/100, Loss: 3.5555\n",
      "Epoch 63/100, Loss: 1.8103\n",
      "Epoch 64/100, Loss: 4.0465\n",
      "Epoch 65/100, Loss: 4.0873\n",
      "Epoch 66/100, Loss: 5.0351\n",
      "Epoch 67/100, Loss: 4.7415\n",
      "Epoch 68/100, Loss: 4.6695\n",
      "Epoch 69/100, Loss: 2.5819\n",
      "Epoch 70/100, Loss: 2.1058\n",
      "Epoch 71/100, Loss: 3.8719\n",
      "Epoch 72/100, Loss: 3.6513\n",
      "Epoch 73/100, Loss: 3.9881\n",
      "Epoch 74/100, Loss: 4.4305\n",
      "Epoch 75/100, Loss: 3.7803\n",
      "Epoch 76/100, Loss: 2.0203\n",
      "Epoch 77/100, Loss: 4.8745\n",
      "Epoch 78/100, Loss: 4.9738\n",
      "Epoch 79/100, Loss: 3.8140\n",
      "Epoch 80/100, Loss: 3.0745\n",
      "Epoch 81/100, Loss: 5.3325\n",
      "Epoch 82/100, Loss: 3.8505\n",
      "Epoch 83/100, Loss: 5.8934\n",
      "Epoch 84/100, Loss: 4.3229\n",
      "Epoch 85/100, Loss: 4.3292\n",
      "Epoch 86/100, Loss: 4.4295\n",
      "Epoch 87/100, Loss: 4.6569\n",
      "Epoch 88/100, Loss: 2.7595\n",
      "Epoch 89/100, Loss: 4.9768\n",
      "Epoch 90/100, Loss: 3.6673\n",
      "Epoch 91/100, Loss: 4.7192\n",
      "Epoch 92/100, Loss: 2.4070\n",
      "Epoch 93/100, Loss: 2.5989\n",
      "Epoch 94/100, Loss: 2.3279\n",
      "Epoch 95/100, Loss: 3.2066\n",
      "Epoch 96/100, Loss: 2.1196\n",
      "Epoch 97/100, Loss: 3.0251\n",
      "Epoch 98/100, Loss: 5.3801\n",
      "Epoch 99/100, Loss: 3.0723\n",
      "Epoch 100/100, Loss: 3.9336\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Define the dataset\n",
    "class SineDataset(Dataset):\n",
    "    def __init__(self, num_functions=100, num_points=50, noise_level=0.1):\n",
    "        \"\"\"\n",
    "        Initialize the sine wave dataset.\n",
    "        Args:\n",
    "            num_functions (int): Number of sine wave functions in the dataset.\n",
    "            num_points (int): Number of points per sine wave.\n",
    "            noise_level (float): Standard deviation of noise added to the data.\n",
    "        \"\"\"\n",
    "        self.num_functions = num_functions\n",
    "        self.num_points = num_points\n",
    "        self.noise_level = noise_level\n",
    "        self.data = []\n",
    "        for _ in range(num_functions):\n",
    "            # Random amplitude and phase for sine waves\n",
    "            amplitude = np.random.uniform(0.5, 2.0)\n",
    "            phase = np.random.uniform(0, np.pi)\n",
    "            x = np.linspace(-np.pi, np.pi, num_points)\n",
    "            y = amplitude * np.sin(x + phase) + np.random.normal(0, noise_level, num_points)\n",
    "            self.data.append((x, y))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.data[idx]\n",
    "        return torch.tensor(x, dtype=torch.float32).unsqueeze(-1), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Define the ModulatedSSN model\n",
    "class ModulatedSSN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, latent_dim):\n",
    "        \"\"\"\n",
    "        Initialize the modulated SSN model.\n",
    "        Args:\n",
    "            input_dim (int): Dimensionality of the input.\n",
    "            hidden_dim (int): Number of hidden units in the MLP.\n",
    "            output_dim (int): Dimensionality of the output.\n",
    "            latent_dim (int): Dimensionality of the latent code.\n",
    "        \"\"\"\n",
    "        super(ModulatedSSN, self).__init__()\n",
    "        self.latent_to_modulation = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim + hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def modulated_forward(self, coords, latent_code):\n",
    "        \"\"\"\n",
    "        Forward pass with modulation.\n",
    "        Args:\n",
    "            coords (torch.Tensor): Input coordinates (e.g., x values) of shape [B, D].\n",
    "            latent_code (torch.Tensor): Latent code for modulation of shape [L].\n",
    "        \"\"\"\n",
    "        modulation = self.latent_to_modulation(latent_code)  # Shape: [hidden_dim]\n",
    "        modulation = modulation.unsqueeze(0).expand(coords.shape[0], -1)  # Shape: [B, hidden_dim]\n",
    "        modulated_input = torch.cat([coords, modulation], dim=-1)  # Shape: [B, D + hidden_dim]\n",
    "        return self.mlp(modulated_input)\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = 1\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "latent_dim = 16\n",
    "num_epochs = 100\n",
    "batch_size = 16\n",
    "inner_steps = 5\n",
    "inner_lr = 1e-2\n",
    "outer_lr = 1e-3\n",
    "\n",
    "# Create the dataset and model\n",
    "dataset = SineDataset(num_functions=100, num_points=50)\n",
    "model = ModulatedSSN(input_dim, hidden_dim, output_dim, latent_dim)\n",
    "\n",
    "# Create the trainer\n",
    "trainer = CORALTrainer(model=model, latent_dim=latent_dim, learning_rate=outer_lr)\n",
    "\n",
    "# Train the model\n",
    "trainer.train(\n",
    "    dataset=dataset,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    inner_steps=inner_steps,\n",
    "    inner_lr=inner_lr\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2128b507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CORALTrainer at 0x20bd7ab7790>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c90b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
