{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import gc\n",
    "from CORAL_Methods_and_Classes import *\n",
    "\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HrfnaCesAHNR"
   },
   "outputs": [],
   "source": [
    "# set hyperparams here\n",
    "def Train_SIREN_INR(train_dataset, test_dataset, latent_dim, filename, epochs=100):\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "    # Ensure device compatibility\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Instantiate the Modulated SIREN INR\n",
    "    input_dim = 2\n",
    "    hidden_dim = 256\n",
    "    output_dim = 1\n",
    "    num_layers = 4\n",
    "\n",
    "    # params\n",
    "    inner_steps = 3\n",
    "    inner_lr = 1e-5\n",
    "    lr_code = 1e-5\n",
    "    meta_lr_code = 1e-5\n",
    "    weight_decay_code = 0\n",
    "    lr_inr = 1e-4\n",
    "    gamma_step = 0.5\n",
    "    ntrain = len(train_dataset)\n",
    "    ntest = len(test_dataset)\n",
    "    epochs = epochs\n",
    "    RESULTS_DIR = './INR_models_trained/'\n",
    "    run_name = filename\n",
    "\n",
    "    # instantiate ModulatedSiren model with hyperparams\n",
    "    inr = ModulatedSiren(\n",
    "      dim_in=input_dim,\n",
    "      dim_hidden=hidden_dim,\n",
    "      dim_out=output_dim,\n",
    "      num_layers=num_layers,\n",
    "      latent_dim=latent_dim,\n",
    "      modulation_net_dim_hidden=64,\n",
    "      modulation_net_num_layers=2,\n",
    "      modulate_scale=False,\n",
    "      modulate_shift=True,\n",
    "    ).to(device)\n",
    "\n",
    "    # run training loop, which saves the best model\n",
    "    train_inr(\n",
    "      inr=inr,\n",
    "      train_loader=train_loader,\n",
    "      test_loader=test_loader,\n",
    "      latent_dim=latent_dim,\n",
    "      inner_steps=inner_steps,\n",
    "      inner_lr=inner_lr,\n",
    "      lr_code=lr_code,\n",
    "      meta_lr_code=meta_lr_code,\n",
    "      weight_decay_code=weight_decay_code,\n",
    "      lr_inr=lr_inr,\n",
    "      gamma_step=gamma_step,\n",
    "      ntrain=ntrain,\n",
    "      ntest=ntest,\n",
    "      epochs=epochs,\n",
    "      saved_checkpoint=False,\n",
    "      checkpoint=None,\n",
    "      RESULTS_DIR=RESULTS_DIR,\n",
    "      run_name=run_name,\n",
    "      device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DXY8Ifu-KjVD",
    "outputId": "aa162e83-78e2-4a42-e2bc-d9a6e38ef31a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "triangle 0.1 ----------------------------------------------------------------------------------------------------\n",
      "epoch = 0; train_loss = 60.58953491210937; test_loss=51.46541198730469\n",
      "save model\n",
      "epoch = 1; train_loss = 42.16449749755859; test_loss=35.97215118408203\n",
      "save model\n",
      "epoch = 2; train_loss = 29.696978454589843; test_loss=25.817020568847656\n",
      "save model\n",
      "epoch = 3; train_loss = 21.11116795349121; test_loss=17.11549301147461\n",
      "save model\n",
      "epoch = 4; train_loss = 13.067118400573731; test_loss=9.693951683044434\n",
      "save model\n",
      "epoch = 5; train_loss = 6.9820072517395015; test_loss=4.712105655670166\n",
      "save model\n",
      "epoch = 6; train_loss = 3.4822229747772218; test_loss=2.5702927923202514\n",
      "save model\n",
      "epoch = 7; train_loss = 2.270056447982788; test_loss=1.993308620452881\n",
      "save model\n",
      "epoch = 8; train_loss = 1.9652873163223266; test_loss=1.9833534622192384\n",
      "save model\n",
      "epoch = 9; train_loss = 1.826489981651306; test_loss=1.739971833229065\n",
      "save model\n",
      "epoch = 10; train_loss = 1.7072689933776855; test_loss=1.6725576496124268\n",
      "save model\n",
      "epoch = 11; train_loss = 1.8240035591125487; test_loss=1.7051583194732667\n",
      "epoch = 12; train_loss = 1.5595521450042724; test_loss=1.5541970014572144\n",
      "save model\n",
      "epoch = 13; train_loss = 1.486817258834839; test_loss=1.5009289860725403\n",
      "save model\n",
      "epoch = 14; train_loss = 1.8398559808731079; test_loss=1.960851058959961\n",
      "epoch = 15; train_loss = 1.6416406269073487; test_loss=1.5676455068588258\n",
      "epoch = 16; train_loss = 1.6474955129623412; test_loss=1.5331968402862548\n",
      "epoch = 17; train_loss = 1.405469506263733; test_loss=1.4536615300178528\n",
      "save model\n",
      "epoch = 18; train_loss = 1.3394177227020263; test_loss=1.4697700023651123\n",
      "save model\n",
      "epoch = 19; train_loss = 1.443782374382019; test_loss=1.6906469535827637\n",
      "epoch = 20; train_loss = 1.5908600416183472; test_loss=1.491110348701477\n",
      "epoch = 21; train_loss = 1.2770000667572021; test_loss=1.3978125333786011\n",
      "save model\n",
      "epoch = 22; train_loss = 1.208088200569153; test_loss=1.4340063810348511\n",
      "save model\n",
      "epoch = 23; train_loss = 1.1511769514083863; test_loss=1.3425266313552857\n",
      "save model\n",
      "epoch = 24; train_loss = 1.2454189224243164; test_loss=1.5131944084167481\n",
      "epoch = 25; train_loss = 1.1966943373680115; test_loss=1.453618745803833\n",
      "epoch = 26; train_loss = 1.169542067527771; test_loss=1.3744555521011352\n",
      "epoch = 27; train_loss = 1.0430580415725708; test_loss=1.3672606086730956\n",
      "save model\n",
      "epoch = 28; train_loss = 1.0940010023117066; test_loss=1.3406152963638305\n",
      "epoch = 29; train_loss = 1.0376612391471862; test_loss=1.3694940280914307\n",
      "save model\n",
      "epoch = 30; train_loss = 1.0584600067138672; test_loss=1.3809610176086426\n",
      "epoch = 31; train_loss = 1.0521982555389404; test_loss=1.323384017944336\n",
      "epoch = 32; train_loss = 0.9970454969406128; test_loss=1.2833866596221923\n",
      "save model\n",
      "epoch = 33; train_loss = 1.100793351173401; test_loss=1.3328968715667724\n",
      "epoch = 34; train_loss = 1.0172994027137756; test_loss=1.5175331783294679\n",
      "epoch = 35; train_loss = 1.0710099005699159; test_loss=1.4258755397796632\n",
      "epoch = 36; train_loss = 0.99133376121521; test_loss=1.411411190032959\n",
      "save model\n",
      "epoch = 37; train_loss = 0.956991973400116; test_loss=1.4311682510375976\n",
      "save model\n",
      "epoch = 38; train_loss = 0.9161091074943543; test_loss=1.31129319190979\n",
      "save model\n",
      "epoch = 39; train_loss = 0.9736996722221375; test_loss=1.3262363290786743\n",
      "epoch = 40; train_loss = 0.8846258716583252; test_loss=1.3752810621261597\n",
      "save model\n",
      "epoch = 41; train_loss = 0.8722143549919128; test_loss=1.3010468769073487\n",
      "save model\n",
      "epoch = 42; train_loss = 0.8531969208717346; test_loss=1.3637593960762024\n",
      "save model\n",
      "epoch = 43; train_loss = 0.8671888213157654; test_loss=1.3414040637016296\n",
      "epoch = 44; train_loss = 0.9560518527030945; test_loss=1.5854353857040406\n",
      "epoch = 45; train_loss = 1.0969563307762147; test_loss=1.4215750122070312\n",
      "epoch = 46; train_loss = 0.975461531162262; test_loss=1.3178080582618714\n",
      "epoch = 47; train_loss = 0.9089877190589905; test_loss=1.4537562155723571\n",
      "epoch = 48; train_loss = 0.8874855513572693; test_loss=1.3677699327468873\n",
      "epoch = 49; train_loss = 0.8721134305000305; test_loss=1.4345436930656432\n",
      "epoch = 0; train_loss = 523.0473425292969; test_loss=464.916259765625\n",
      "save model\n",
      "epoch = 1; train_loss = 479.8959991455078; test_loss=427.5313513183594\n",
      "save model\n",
      "epoch = 2; train_loss = 440.8035015869141; test_loss=387.8093212890625\n",
      "save model\n",
      "epoch = 3; train_loss = 401.3480682373047; test_loss=353.7690185546875\n",
      "save model\n",
      "epoch = 4; train_loss = 367.1601943359375; test_loss=322.73114624023435\n",
      "save model\n",
      "epoch = 5; train_loss = 335.6361907958984; test_loss=293.88666259765625\n",
      "save model\n",
      "epoch = 6; train_loss = 306.0052529296875; test_loss=266.6706237792969\n",
      "save model\n",
      "epoch = 7; train_loss = 278.29340435791016; test_loss=241.54569885253906\n",
      "save model\n",
      "epoch = 8; train_loss = 252.6968857421875; test_loss=218.2445147705078\n",
      "save model\n",
      "epoch = 9; train_loss = 228.98638159179689; test_loss=196.79296447753907\n",
      "save model\n",
      "epoch = 10; train_loss = 207.04991003417967; test_loss=177.01898376464842\n",
      "save model\n",
      "epoch = 11; train_loss = 186.73374237060546; test_loss=158.83586181640624\n",
      "save model\n",
      "epoch = 12; train_loss = 167.98730053710938; test_loss=142.04854858398437\n",
      "save model\n",
      "epoch = 13; train_loss = 150.63489279174806; test_loss=126.55377807617188\n",
      "save model\n",
      "epoch = 14; train_loss = 134.59845922851562; test_loss=112.38812744140625\n",
      "save model\n",
      "epoch = 15; train_loss = 119.85209321594239; test_loss=99.34261047363282\n",
      "save model\n",
      "epoch = 16; train_loss = 106.3010606994629; test_loss=87.44040344238282\n",
      "save model\n",
      "epoch = 17; train_loss = 93.8773543548584; test_loss=76.65258911132813\n",
      "save model\n",
      "epoch = 18; train_loss = 82.52242405700683; test_loss=66.802578125\n",
      "save model\n",
      "epoch = 19; train_loss = 72.18237996673584; test_loss=57.96048461914062\n",
      "save model\n",
      "epoch = 20; train_loss = 62.823134674072264; test_loss=49.96272033691406\n",
      "save model\n",
      "epoch = 21; train_loss = 54.321481620788575; test_loss=42.81668395996094\n",
      "save model\n",
      "epoch = 22; train_loss = 46.71772892379761; test_loss=36.51744766235352\n",
      "save model\n",
      "epoch = 23; train_loss = 39.8782163772583; test_loss=30.8395654296875\n",
      "save model\n",
      "epoch = 24; train_loss = 33.805452341079715; test_loss=25.848222579956055\n",
      "save model\n",
      "epoch = 25; train_loss = 28.411981006622316; test_loss=21.47905731201172\n",
      "save model\n",
      "epoch = 26; train_loss = 23.70676092529297; test_loss=17.745243911743163\n",
      "save model\n",
      "epoch = 27; train_loss = 19.584603992462156; test_loss=14.480197563171387\n",
      "save model\n",
      "epoch = 28; train_loss = 16.021428045272827; test_loss=11.706485786437987\n",
      "save model\n",
      "epoch = 29; train_loss = 12.991314867973328; test_loss=9.404338302612304\n",
      "save model\n",
      "epoch = 30; train_loss = 10.44632142305374; test_loss=7.454272613525391\n",
      "save model\n",
      "epoch = 31; train_loss = 8.358384037494659; test_loss=5.897511463165284\n",
      "save model\n",
      "epoch = 32; train_loss = 6.667239566326141; test_loss=4.68899299621582\n",
      "save model\n",
      "epoch = 33; train_loss = 5.302759758234024; test_loss=3.691298017501831\n",
      "save model\n",
      "epoch = 34; train_loss = 4.205786145687103; test_loss=2.9360519218444825\n",
      "save model\n",
      "epoch = 35; train_loss = 3.358174472808838; test_loss=2.3633796310424806\n",
      "save model\n",
      "epoch = 36; train_loss = 2.706159436941147; test_loss=1.9082405185699463\n",
      "save model\n",
      "epoch = 37; train_loss = 2.1985895700454714; test_loss=1.5723640394210816\n",
      "save model\n",
      "epoch = 38; train_loss = 1.8134335794448853; test_loss=1.3192900037765503\n",
      "save model\n",
      "epoch = 39; train_loss = 1.514941474199295; test_loss=1.1252912282943726\n",
      "save model\n",
      "epoch = 40; train_loss = 1.2821990883350372; test_loss=0.9817087650299072\n",
      "save model\n",
      "epoch = 41; train_loss = 1.1004029873609542; test_loss=0.8699994897842407\n",
      "save model\n",
      "epoch = 42; train_loss = 0.9501265522241592; test_loss=0.7485902738571167\n",
      "save model\n",
      "epoch = 43; train_loss = 0.8269327760934829; test_loss=0.6611795616149903\n",
      "save model\n",
      "epoch = 44; train_loss = 0.7253526573181153; test_loss=0.5999563312530518\n",
      "save model\n",
      "epoch = 45; train_loss = 0.6468009065389633; test_loss=0.5492264890670776\n",
      "save model\n",
      "epoch = 46; train_loss = 0.5754199044704438; test_loss=0.5035869598388671\n",
      "save model\n",
      "epoch = 47; train_loss = 0.5214458475112915; test_loss=0.47735183000564574\n",
      "save model\n",
      "epoch = 48; train_loss = 0.47654229724407193; test_loss=0.44030304431915285\n",
      "save model\n",
      "epoch = 49; train_loss = 0.4274402335882187; test_loss=0.40296280026435854\n",
      "save model\n",
      "triangle 0.5 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0; train_loss = 59.98656079101563; test_loss=46.193968048095705\n",
      "save model\n",
      "epoch = 1; train_loss = 41.784460662841795; test_loss=32.340176849365236\n",
      "save model\n",
      "epoch = 2; train_loss = 29.549157012939453; test_loss=23.646775817871095\n",
      "save model\n",
      "epoch = 3; train_loss = 20.64802149963379; test_loss=14.715296516418457\n",
      "save model\n",
      "epoch = 4; train_loss = 12.622752128601075; test_loss=8.190580558776855\n",
      "save model\n",
      "epoch = 5; train_loss = 6.853143733978271; test_loss=3.979929218292236\n",
      "save model\n",
      "epoch = 6; train_loss = 3.5534858226776125; test_loss=2.281143236160278\n",
      "save model\n",
      "epoch = 7; train_loss = 2.7270619859695433; test_loss=2.016490840911865\n",
      "save model\n",
      "epoch = 8; train_loss = 2.405266471862793; test_loss=1.9027437114715575\n",
      "save model\n",
      "epoch = 9; train_loss = 2.279712173461914; test_loss=1.8413267755508422\n",
      "save model\n",
      "epoch = 10; train_loss = 2.2015649900436403; test_loss=1.8135796117782592\n",
      "save model\n",
      "epoch = 11; train_loss = 2.1712128982543946; test_loss=2.04972692489624\n",
      "save model\n",
      "epoch = 12; train_loss = 2.281057195663452; test_loss=1.7385535621643067\n",
      "epoch = 13; train_loss = 2.033836151123047; test_loss=1.6821146249771117\n",
      "save model\n",
      "epoch = 14; train_loss = 1.9724450979232788; test_loss=1.6942025470733642\n",
      "save model\n",
      "epoch = 15; train_loss = 1.9390718879699707; test_loss=1.624179801940918\n",
      "save model\n",
      "epoch = 16; train_loss = 1.8855342807769775; test_loss=1.6704522800445556\n",
      "save model\n",
      "epoch = 17; train_loss = 1.8822869358062744; test_loss=1.6422245740890502\n",
      "save model\n",
      "epoch = 18; train_loss = 1.8375133533477783; test_loss=1.591549458503723\n",
      "save model\n",
      "epoch = 19; train_loss = 1.8741557683944703; test_loss=1.5981480884552002\n",
      "epoch = 20; train_loss = 1.7546966400146484; test_loss=1.5388053703308104\n",
      "save model\n",
      "epoch = 21; train_loss = 1.7129212369918823; test_loss=1.4948609733581544\n",
      "save model\n",
      "epoch = 22; train_loss = 1.7214438829421996; test_loss=1.9332639837265015\n",
      "epoch = 23; train_loss = 1.8220487909317016; test_loss=1.4570287799835204\n",
      "epoch = 24; train_loss = 1.6275907955169677; test_loss=1.4669619226455688\n",
      "save model\n",
      "epoch = 25; train_loss = 1.6707825555801392; test_loss=1.4975277471542359\n",
      "epoch = 26; train_loss = 1.5903503303527833; test_loss=1.4850911712646484\n",
      "save model\n",
      "epoch = 27; train_loss = 1.5998228349685668; test_loss=1.5165803480148314\n",
      "epoch = 28; train_loss = 1.5676180982589722; test_loss=1.485881862640381\n",
      "save model\n",
      "epoch = 29; train_loss = 1.5527871527671815; test_loss=1.4345325469970702\n",
      "save model\n",
      "epoch = 30; train_loss = 1.5714028263092041; test_loss=1.554332971572876\n",
      "epoch = 31; train_loss = 1.573069869995117; test_loss=1.4357325315475464\n",
      "epoch = 32; train_loss = 1.531383466720581; test_loss=1.4455418872833252\n",
      "save model\n",
      "epoch = 33; train_loss = 1.4847436490058898; test_loss=1.5217996788024903\n",
      "save model\n",
      "epoch = 34; train_loss = 1.484860538959503; test_loss=1.4937528705596923\n",
      "epoch = 35; train_loss = 1.4564258327484132; test_loss=1.471381573677063\n",
      "save model\n",
      "epoch = 36; train_loss = 1.5143357090950011; test_loss=1.529597897529602\n",
      "epoch = 37; train_loss = 1.497712911605835; test_loss=1.4426889944076537\n",
      "epoch = 38; train_loss = 1.4438618898391724; test_loss=1.5624485301971436\n",
      "save model\n",
      "epoch = 39; train_loss = 1.4944738121032715; test_loss=1.4468506002426147\n",
      "epoch = 40; train_loss = 1.3831491985321045; test_loss=1.4506064891815185\n",
      "save model\n",
      "epoch = 41; train_loss = 1.4628329601287842; test_loss=1.6085342216491698\n",
      "epoch = 42; train_loss = 1.439153573513031; test_loss=1.4781504964828491\n",
      "epoch = 43; train_loss = 1.393161105632782; test_loss=1.4906190967559814\n",
      "epoch = 44; train_loss = 1.327491542339325; test_loss=1.450776743888855\n",
      "save model\n",
      "epoch = 45; train_loss = 1.414842734336853; test_loss=1.5391898202896117\n",
      "epoch = 46; train_loss = 1.3863893899917603; test_loss=1.5034090280532837\n",
      "epoch = 47; train_loss = 1.3211928482055664; test_loss=1.4865198707580567\n",
      "save model\n",
      "epoch = 48; train_loss = 1.3433413743972777; test_loss=1.4571272706985474\n",
      "epoch = 49; train_loss = 1.285957375049591; test_loss=1.451124873161316\n",
      "save model\n",
      "epoch = 0; train_loss = 579.0152700195313; test_loss=661.9444018554688\n",
      "save model\n",
      "epoch = 1; train_loss = 531.277829711914; test_loss=612.8276574707031\n",
      "save model\n",
      "epoch = 2; train_loss = 488.7271896362305; test_loss=562.8658892822266\n",
      "save model\n",
      "epoch = 3; train_loss = 446.3679019165039; test_loss=516.7626733398438\n",
      "save model\n",
      "epoch = 4; train_loss = 408.57985137939454; test_loss=474.7342236328125\n",
      "save model\n",
      "epoch = 5; train_loss = 374.0437902832031; test_loss=435.62440307617186\n",
      "save model\n",
      "epoch = 6; train_loss = 341.56113635253905; test_loss=398.7854113769531\n",
      "save model\n",
      "epoch = 7; train_loss = 311.0153386230469; test_loss=363.85965454101563\n",
      "save model\n",
      "epoch = 8; train_loss = 282.6236322631836; test_loss=331.47774291992187\n",
      "save model\n",
      "epoch = 9; train_loss = 256.281073059082; test_loss=301.148037109375\n",
      "save model\n",
      "epoch = 10; train_loss = 231.83815139770508; test_loss=273.0056686401367\n",
      "save model\n",
      "epoch = 11; train_loss = 209.18350161743163; test_loss=246.79680755615234\n",
      "save model\n",
      "epoch = 12; train_loss = 188.23788580322267; test_loss=222.4089761352539\n",
      "save model\n",
      "epoch = 13; train_loss = 168.9147286376953; test_loss=199.94892456054689\n",
      "save model\n",
      "epoch = 14; train_loss = 151.09485696411133; test_loss=179.03540557861328\n",
      "save model\n",
      "epoch = 15; train_loss = 134.6841321105957; test_loss=159.85165557861328\n",
      "save model\n",
      "epoch = 16; train_loss = 119.63665335083007; test_loss=142.23865127563477\n",
      "save model\n",
      "epoch = 17; train_loss = 105.87409799194336; test_loss=126.02860733032226\n",
      "save model\n",
      "epoch = 18; train_loss = 93.3014722290039; test_loss=111.20061325073242\n",
      "save model\n",
      "epoch = 19; train_loss = 81.80528936767578; test_loss=97.5468701171875\n",
      "save model\n",
      "epoch = 20; train_loss = 71.39606256103515; test_loss=85.23414566040039\n",
      "save model\n",
      "epoch = 21; train_loss = 61.96467024230957; test_loss=74.01341018676757\n",
      "save model\n",
      "epoch = 22; train_loss = 53.488417610168455; test_loss=63.9574242401123\n",
      "save model\n",
      "epoch = 23; train_loss = 45.88306843185425; test_loss=54.9677702331543\n",
      "save model\n",
      "epoch = 24; train_loss = 39.11247577667236; test_loss=46.89634002685547\n",
      "save model\n",
      "epoch = 25; train_loss = 33.087658348083494; test_loss=39.62616104125976\n",
      "save model\n",
      "epoch = 26; train_loss = 27.738211891174316; test_loss=33.18584934234619\n",
      "save model\n",
      "epoch = 27; train_loss = 23.047830240249635; test_loss=27.594605560302735\n",
      "save model\n",
      "epoch = 28; train_loss = 18.964599159240723; test_loss=22.623925895690917\n",
      "save model\n",
      "epoch = 29; train_loss = 15.416070203781128; test_loss=18.354939098358155\n",
      "save model\n",
      "epoch = 30; train_loss = 12.381165283203124; test_loss=14.746485271453857\n",
      "save model\n",
      "epoch = 31; train_loss = 9.858770812511445; test_loss=11.758357734680176\n",
      "save model\n",
      "epoch = 32; train_loss = 7.802905966043472; test_loss=9.294877834320069\n",
      "save model\n",
      "epoch = 33; train_loss = 6.139101911783218; test_loss=7.2863508892059325\n",
      "save model\n",
      "epoch = 34; train_loss = 4.810581499814988; test_loss=5.761192111968994\n",
      "save model\n",
      "epoch = 35; train_loss = 3.7891834510564806; test_loss=4.550805444717407\n",
      "save model\n",
      "epoch = 36; train_loss = 2.9899453016519546; test_loss=3.6039504766464234\n",
      "save model\n",
      "epoch = 37; train_loss = 2.387583966255188; test_loss=2.9036693382263183\n",
      "save model\n",
      "epoch = 38; train_loss = 1.9516089551448823; test_loss=2.3906349182128905\n",
      "save model\n",
      "epoch = 39; train_loss = 1.6572315542697906; test_loss=2.0404582977294923\n",
      "save model\n",
      "epoch = 40; train_loss = 1.3770902532339095; test_loss=1.695519313812256\n",
      "save model\n",
      "epoch = 41; train_loss = 1.1668093537092208; test_loss=1.4532004356384278\n",
      "save model\n",
      "epoch = 42; train_loss = 1.007191258072853; test_loss=1.2520136547088623\n",
      "save model\n",
      "epoch = 43; train_loss = 0.8776732649803162; test_loss=1.106200439929962\n",
      "save model\n",
      "epoch = 44; train_loss = 0.7745721695423127; test_loss=0.9578174781799317\n",
      "save model\n",
      "epoch = 45; train_loss = 0.6862525607347488; test_loss=0.8723401808738709\n",
      "save model\n",
      "epoch = 46; train_loss = 0.6221092479228973; test_loss=0.7777741384506226\n",
      "save model\n",
      "epoch = 47; train_loss = 0.5669103496074677; test_loss=0.6887251782417297\n",
      "save model\n",
      "epoch = 48; train_loss = 0.5123576866388321; test_loss=0.6180911123752594\n",
      "save model\n",
      "epoch = 49; train_loss = 0.47380900621414185; test_loss=0.5813738083839417\n",
      "save model\n",
      "bean 0.1 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0; train_loss = 60.848320343017576; test_loss=50.258057861328126\n",
      "save model\n",
      "epoch = 1; train_loss = 42.37622311401367; test_loss=35.20178634643555\n",
      "save model\n",
      "epoch = 2; train_loss = 29.752866088867187; test_loss=25.26053939819336\n",
      "save model\n",
      "epoch = 3; train_loss = 20.608127990722657; test_loss=16.135546798706056\n",
      "save model\n",
      "epoch = 4; train_loss = 12.437546264648438; test_loss=9.100267066955567\n",
      "save model\n",
      "epoch = 5; train_loss = 6.563810497283936; test_loss=4.448033752441407\n",
      "save model\n",
      "epoch = 6; train_loss = 3.193362112045288; test_loss=2.449841241836548\n",
      "save model\n",
      "epoch = 7; train_loss = 2.1281088247299196; test_loss=2.0066148233413696\n",
      "save model\n",
      "epoch = 8; train_loss = 1.8868294801712036; test_loss=1.9697113513946534\n",
      "save model\n",
      "epoch = 9; train_loss = 2.0570208463668824; test_loss=2.003126893043518\n",
      "epoch = 10; train_loss = 1.8820096130371093; test_loss=1.8243400573730468\n",
      "save model\n",
      "epoch = 11; train_loss = 2.217888611793518; test_loss=2.332285943031311\n",
      "epoch = 12; train_loss = 2.074942554473877; test_loss=2.0693822479248047\n",
      "epoch = 13; train_loss = 1.7761140975952148; test_loss=1.752873091697693\n",
      "save model\n",
      "epoch = 14; train_loss = 1.5355317845344543; test_loss=1.6294347620010377\n",
      "save model\n",
      "epoch = 15; train_loss = 1.5150708856582642; test_loss=2.451596584320068\n",
      "save model\n",
      "epoch = 16; train_loss = 1.6511349697113038; test_loss=1.533408408164978\n",
      "epoch = 17; train_loss = 1.3384182224273682; test_loss=1.5112331247329711\n",
      "save model\n",
      "epoch = 18; train_loss = 1.2827686576843262; test_loss=1.4422038555145265\n",
      "save model\n",
      "epoch = 19; train_loss = 1.267935359954834; test_loss=1.4584991931915283\n",
      "save model\n",
      "epoch = 20; train_loss = 1.280658320903778; test_loss=1.3722748470306396\n",
      "epoch = 21; train_loss = 1.3511795835494995; test_loss=1.513867564201355\n",
      "epoch = 22; train_loss = 1.174407645225525; test_loss=1.3230101823806764\n",
      "save model\n",
      "epoch = 23; train_loss = 1.199812530040741; test_loss=1.529138617515564\n",
      "epoch = 24; train_loss = 1.137413504600525; test_loss=1.3408757495880126\n",
      "save model\n",
      "epoch = 25; train_loss = 1.1234693326950074; test_loss=1.41285982131958\n",
      "save model\n",
      "epoch = 26; train_loss = 1.044641930580139; test_loss=1.2993785619735718\n",
      "save model\n",
      "epoch = 27; train_loss = 1.324270800590515; test_loss=1.831741418838501\n",
      "epoch = 28; train_loss = 1.2999323563575744; test_loss=1.3278690195083618\n",
      "epoch = 29; train_loss = 0.9789994020462036; test_loss=1.2537163448333741\n",
      "save model\n",
      "epoch = 30; train_loss = 0.9637149243354798; test_loss=1.313712158203125\n",
      "save model\n",
      "epoch = 31; train_loss = 0.9292711956501007; test_loss=1.2526505422592162\n",
      "save model\n",
      "epoch = 32; train_loss = 0.904162563085556; test_loss=1.3142636728286743\n",
      "save model\n",
      "epoch = 33; train_loss = 0.8700987720489501; test_loss=1.2714395999908448\n",
      "save model\n",
      "epoch = 34; train_loss = 0.8872895781993866; test_loss=1.207362914085388\n",
      "epoch = 35; train_loss = 0.8214025831222534; test_loss=1.2017144298553466\n",
      "save model\n",
      "epoch = 36; train_loss = 0.9505414204597473; test_loss=1.364017596244812\n",
      "epoch = 37; train_loss = 0.9465209403038025; test_loss=1.3964327001571655\n",
      "epoch = 38; train_loss = 0.9015591366291046; test_loss=1.2791027784347535\n",
      "epoch = 39; train_loss = 0.8611716942787171; test_loss=1.2825985336303711\n",
      "epoch = 40; train_loss = 0.9035740249156952; test_loss=1.2834377956390381\n",
      "epoch = 41; train_loss = 0.7835887522697449; test_loss=1.2403513717651367\n",
      "save model\n",
      "epoch = 42; train_loss = 0.8090954303741456; test_loss=1.3305372285842896\n",
      "epoch = 43; train_loss = 0.7951377093791961; test_loss=1.295012319087982\n",
      "epoch = 44; train_loss = 0.8459564559459686; test_loss=1.3240148329734802\n",
      "epoch = 45; train_loss = 0.7854460229873658; test_loss=1.2480160260200501\n",
      "epoch = 46; train_loss = 0.8021625463962555; test_loss=1.3363802528381348\n",
      "epoch = 47; train_loss = 0.8211407630443573; test_loss=1.3017088079452515\n",
      "epoch = 48; train_loss = 0.698810157775879; test_loss=1.2255125498771668\n",
      "save model\n",
      "epoch = 49; train_loss = 0.7185113191604614; test_loss=1.3033355379104614\n",
      "epoch = 0; train_loss = 309.50736755371094; test_loss=278.76793090820314\n",
      "save model\n",
      "epoch = 1; train_loss = 275.1498409423828; test_loss=248.68651489257812\n",
      "save model\n",
      "epoch = 2; train_loss = 243.57373388671874; test_loss=215.60699951171875\n",
      "save model\n",
      "epoch = 3; train_loss = 213.2543231201172; test_loss=188.99868530273437\n",
      "save model\n",
      "epoch = 4; train_loss = 187.6543115234375; test_loss=165.1188818359375\n",
      "save model\n",
      "epoch = 5; train_loss = 164.30644567871093; test_loss=143.38735168457032\n",
      "save model\n",
      "epoch = 6; train_loss = 143.02278674316406; test_loss=123.80775451660156\n",
      "save model\n",
      "epoch = 7; train_loss = 123.62663818359376; test_loss=106.07197723388671\n",
      "save model\n",
      "epoch = 8; train_loss = 106.20889001464843; test_loss=90.26701416015625\n",
      "save model\n",
      "epoch = 9; train_loss = 90.63271398925781; test_loss=76.21140991210937\n",
      "save model\n",
      "epoch = 10; train_loss = 76.70513098144531; test_loss=63.83130584716797\n",
      "save model\n",
      "epoch = 11; train_loss = 64.36834362792969; test_loss=52.97402725219727\n",
      "save model\n",
      "epoch = 12; train_loss = 53.51129672241211; test_loss=43.47900894165039\n",
      "save model\n",
      "epoch = 13; train_loss = 43.92482893371582; test_loss=35.23246200561523\n",
      "save model\n",
      "epoch = 14; train_loss = 35.59701383972168; test_loss=28.148570098876952\n",
      "save model\n",
      "epoch = 15; train_loss = 28.42662121582031; test_loss=22.121776275634765\n",
      "save model\n",
      "epoch = 16; train_loss = 22.299676635742188; test_loss=17.121888275146485\n",
      "save model\n",
      "epoch = 17; train_loss = 17.13884354400635; test_loss=12.87594383239746\n",
      "save model\n",
      "epoch = 18; train_loss = 12.840047218322754; test_loss=9.476651153564454\n",
      "save model\n",
      "epoch = 19; train_loss = 9.374205821990968; test_loss=6.773713722229004\n",
      "save model\n",
      "epoch = 20; train_loss = 6.646543937683106; test_loss=4.7009720039367675\n",
      "save model\n",
      "epoch = 21; train_loss = 4.609043182373047; test_loss=3.241950283050537\n",
      "save model\n",
      "epoch = 22; train_loss = 3.133403305053711; test_loss=2.204123058319092\n",
      "save model\n",
      "epoch = 23; train_loss = 2.154236389160156; test_loss=1.5515907287597657\n",
      "save model\n",
      "epoch = 24; train_loss = 1.5306089758872985; test_loss=1.1245485925674439\n",
      "save model\n",
      "epoch = 25; train_loss = 1.1230475130081177; test_loss=0.8661183643341065\n",
      "save model\n",
      "epoch = 26; train_loss = 0.8609076364040374; test_loss=0.6881301975250245\n",
      "save model\n",
      "epoch = 27; train_loss = 0.6844325187206268; test_loss=0.5567833495140075\n",
      "save model\n",
      "epoch = 28; train_loss = 0.5522304518222809; test_loss=0.46449878692626956\n",
      "save model\n",
      "epoch = 29; train_loss = 0.4566612527370453; test_loss=0.39513092875480654\n",
      "save model\n",
      "epoch = 30; train_loss = 0.38863116335868836; test_loss=0.3492234861850739\n",
      "save model\n",
      "epoch = 31; train_loss = 0.3411051019430161; test_loss=0.3114553034305573\n",
      "save model\n",
      "epoch = 32; train_loss = 0.29722815787792206; test_loss=0.2830477046966553\n",
      "save model\n",
      "epoch = 33; train_loss = 0.2646517540216446; test_loss=0.2565801668167114\n",
      "save model\n",
      "epoch = 34; train_loss = 0.23719487714767457; test_loss=0.23591171741485595\n",
      "save model\n",
      "epoch = 35; train_loss = 0.21654770588874817; test_loss=0.21966211915016173\n",
      "save model\n",
      "epoch = 36; train_loss = 0.20153467214107512; test_loss=0.21304081320762636\n",
      "save model\n",
      "epoch = 37; train_loss = 0.19482117664813994; test_loss=0.204347163438797\n",
      "save model\n",
      "epoch = 38; train_loss = 0.17820361506938934; test_loss=0.1926313579082489\n",
      "save model\n",
      "epoch = 39; train_loss = 0.16883800137042998; test_loss=0.18498324930667878\n",
      "save model\n",
      "epoch = 40; train_loss = 0.15823239934444427; test_loss=0.177726371884346\n",
      "save model\n",
      "epoch = 41; train_loss = 0.14862633156776428; test_loss=0.17595568299293518\n",
      "save model\n",
      "epoch = 42; train_loss = 0.142985593855381; test_loss=0.17671983420848847\n",
      "save model\n",
      "epoch = 43; train_loss = 0.14035705351829528; test_loss=0.18979911565780638\n",
      "save model\n",
      "epoch = 44; train_loss = 0.13963245981931685; test_loss=0.1720784091949463\n",
      "save model\n",
      "epoch = 45; train_loss = 0.13099472737312318; test_loss=0.17184860706329347\n",
      "save model\n",
      "epoch = 46; train_loss = 0.12864076977968217; test_loss=0.1610494750738144\n",
      "save model\n",
      "epoch = 47; train_loss = 0.12612511694431305; test_loss=0.16423229217529298\n",
      "save model\n",
      "epoch = 48; train_loss = 0.1255656636953354; test_loss=0.16617132365703582\n",
      "save model\n",
      "epoch = 49; train_loss = 0.11787122589349747; test_loss=0.15810407996177672\n",
      "save model\n",
      "bean 0.5 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0; train_loss = 59.6065329284668; test_loss=47.63971649169922\n",
      "save model\n",
      "epoch = 1; train_loss = 41.486289154052734; test_loss=33.301532135009765\n",
      "save model\n",
      "epoch = 2; train_loss = 29.332801208496093; test_loss=24.36581619262695\n",
      "save model\n",
      "epoch = 3; train_loss = 20.10162289428711; test_loss=15.576829299926757\n",
      "save model\n",
      "epoch = 4; train_loss = 12.410514129638672; test_loss=8.681437339782715\n",
      "save model\n",
      "epoch = 5; train_loss = 6.550437118530273; test_loss=4.279465579986573\n",
      "save model\n",
      "epoch = 6; train_loss = 3.4313197994232176; test_loss=2.4919570159912108\n",
      "save model\n",
      "epoch = 7; train_loss = 2.4725820579528808; test_loss=2.1506924533843996\n",
      "save model\n",
      "epoch = 8; train_loss = 2.4108193264007567; test_loss=2.1661732006073\n",
      "save model\n",
      "epoch = 9; train_loss = 2.1804898452758787; test_loss=1.9580448055267334\n",
      "save model\n",
      "epoch = 10; train_loss = 2.05248148727417; test_loss=1.8910607814788818\n",
      "save model\n",
      "epoch = 11; train_loss = 1.9987102222442628; test_loss=1.899084405899048\n",
      "save model\n",
      "epoch = 12; train_loss = 2.184283655166626; test_loss=1.8328700256347656\n",
      "epoch = 13; train_loss = 1.9515469436645507; test_loss=1.799570550918579\n",
      "save model\n",
      "epoch = 14; train_loss = 1.8781419277191163; test_loss=1.724660439491272\n",
      "save model\n",
      "epoch = 15; train_loss = 1.7911453971862792; test_loss=1.752560076713562\n",
      "save model\n",
      "epoch = 16; train_loss = 1.7775199270248414; test_loss=1.7671893882751464\n",
      "save model\n",
      "epoch = 17; train_loss = 1.7623586778640747; test_loss=1.6820735263824462\n",
      "save model\n",
      "epoch = 18; train_loss = 1.7336968870162963; test_loss=1.6939413166046142\n",
      "save model\n",
      "epoch = 19; train_loss = 1.6560758142471312; test_loss=1.6530526113510131\n",
      "save model\n",
      "epoch = 20; train_loss = 1.6306638975143433; test_loss=1.6200555419921876\n",
      "save model\n",
      "epoch = 21; train_loss = 1.59295534324646; test_loss=1.7399460983276367\n",
      "save model\n",
      "epoch = 22; train_loss = 1.6224494524002075; test_loss=1.5666411924362182\n",
      "epoch = 23; train_loss = 1.5921951694488525; test_loss=1.6282532453536986\n",
      "save model\n",
      "epoch = 24; train_loss = 1.534117525100708; test_loss=1.568066005706787\n",
      "save model\n",
      "epoch = 25; train_loss = 1.6939810638427735; test_loss=1.6496936178207398\n",
      "epoch = 26; train_loss = 1.526311058998108; test_loss=1.6014682054519653\n",
      "save model\n",
      "epoch = 27; train_loss = 1.5156620721817016; test_loss=1.5833870267868042\n",
      "save model\n",
      "epoch = 28; train_loss = 1.455746012687683; test_loss=1.5387855625152589\n",
      "save model\n",
      "epoch = 29; train_loss = 1.4495989351272582; test_loss=1.56446307182312\n",
      "save model\n",
      "epoch = 30; train_loss = 1.4477053499221801; test_loss=1.5935133600234985\n",
      "save model\n",
      "epoch = 31; train_loss = 1.4894821710586548; test_loss=1.595206756591797\n",
      "epoch = 32; train_loss = 1.4387291412353516; test_loss=1.4950129985809326\n",
      "save model\n",
      "epoch = 33; train_loss = 1.3775610265731812; test_loss=1.6023781728744506\n",
      "save model\n",
      "epoch = 34; train_loss = 1.412744688987732; test_loss=1.5247927570343018\n",
      "epoch = 35; train_loss = 1.427064709663391; test_loss=1.5388023948669434\n",
      "epoch = 36; train_loss = 1.356223916053772; test_loss=1.6228921937942504\n",
      "save model\n",
      "epoch = 37; train_loss = 1.381678038597107; test_loss=1.5404459476470946\n",
      "epoch = 38; train_loss = 1.3181969575881958; test_loss=1.5140948963165284\n",
      "save model\n",
      "epoch = 39; train_loss = 1.3238288745880127; test_loss=1.6679146385192871\n",
      "epoch = 40; train_loss = 1.3770657138824463; test_loss=1.601119751930237\n",
      "epoch = 41; train_loss = 1.3462404851913452; test_loss=1.5689379119873046\n",
      "epoch = 42; train_loss = 1.3006827449798584; test_loss=1.5784918451309204\n",
      "save model\n",
      "epoch = 43; train_loss = 1.2863099603652954; test_loss=1.5024565362930298\n",
      "save model\n",
      "epoch = 44; train_loss = 1.3048829174041747; test_loss=1.6308241558074952\n",
      "epoch = 45; train_loss = 1.3003651542663575; test_loss=1.5351497316360474\n",
      "epoch = 46; train_loss = 1.26780726146698; test_loss=1.5873042440414429\n",
      "save model\n",
      "epoch = 47; train_loss = 1.2546685609817505; test_loss=1.5369517278671265\n",
      "save model\n",
      "epoch = 48; train_loss = 1.2219381170272827; test_loss=1.6065361213684082\n",
      "save model\n",
      "epoch = 49; train_loss = 1.2437295303344726; test_loss=1.6018937015533448\n",
      "epoch = 0; train_loss = 305.64029016113284; test_loss=297.66935302734373\n",
      "save model\n",
      "epoch = 1; train_loss = 270.44641076660156; test_loss=264.84635681152344\n",
      "save model\n",
      "epoch = 2; train_loss = 240.16545275878906; test_loss=230.61151824951173\n",
      "save model\n",
      "epoch = 3; train_loss = 208.25382543945312; test_loss=201.56542541503907\n",
      "save model\n",
      "epoch = 4; train_loss = 182.3787578125; test_loss=175.88864990234376\n",
      "save model\n",
      "epoch = 5; train_loss = 158.8975330810547; test_loss=152.43670867919923\n",
      "save model\n",
      "epoch = 6; train_loss = 137.5015146484375; test_loss=131.2196838378906\n",
      "save model\n",
      "epoch = 7; train_loss = 118.19490447998047; test_loss=112.07547225952149\n",
      "save model\n",
      "epoch = 8; train_loss = 100.86764810180664; test_loss=94.96602310180664\n",
      "save model\n",
      "epoch = 9; train_loss = 85.41315942382812; test_loss=79.83786758422852\n",
      "save model\n",
      "epoch = 10; train_loss = 71.73503143310546; test_loss=66.48437255859375\n",
      "save model\n",
      "epoch = 11; train_loss = 59.66434628295899; test_loss=54.82568466186523\n",
      "save model\n",
      "epoch = 12; train_loss = 49.0977961730957; test_loss=44.69069717407226\n",
      "save model\n",
      "epoch = 13; train_loss = 39.92653233337403; test_loss=35.975873146057125\n",
      "save model\n",
      "epoch = 14; train_loss = 32.037212921142576; test_loss=28.5755961227417\n",
      "save model\n",
      "epoch = 15; train_loss = 25.313975708007813; test_loss=22.289794120788574\n",
      "save model\n",
      "epoch = 16; train_loss = 19.652204719543455; test_loss=17.050729732513428\n",
      "save model\n",
      "epoch = 17; train_loss = 14.959092723846435; test_loss=12.820970821380616\n",
      "save model\n",
      "epoch = 18; train_loss = 11.116056629180909; test_loss=9.36690294265747\n",
      "save model\n",
      "epoch = 19; train_loss = 8.070099734306336; test_loss=6.735081653594971\n",
      "save model\n",
      "epoch = 20; train_loss = 5.74811607837677; test_loss=4.7444215631484985\n",
      "save model\n",
      "epoch = 21; train_loss = 4.025673347473145; test_loss=3.2980102109909057\n",
      "save model\n",
      "epoch = 22; train_loss = 2.8174854140281678; test_loss=2.344701199531555\n",
      "save model\n",
      "epoch = 23; train_loss = 2.0251855549812317; test_loss=1.7179758954048157\n",
      "save model\n",
      "epoch = 24; train_loss = 1.5021603713035583; test_loss=1.3221234703063964\n",
      "save model\n",
      "epoch = 25; train_loss = 1.1677771892547608; test_loss=1.0487824892997741\n",
      "save model\n",
      "epoch = 26; train_loss = 0.9258423919677734; test_loss=0.8228941416740417\n",
      "save model\n",
      "epoch = 27; train_loss = 0.7537258114814759; test_loss=0.671022789478302\n",
      "save model\n",
      "epoch = 28; train_loss = 0.6229932873249054; test_loss=0.5660698091983796\n",
      "save model\n",
      "epoch = 29; train_loss = 0.5239010388851166; test_loss=0.492532217502594\n",
      "save model\n",
      "epoch = 30; train_loss = 0.45176364755630494; test_loss=0.4300185513496399\n",
      "save model\n",
      "epoch = 31; train_loss = 0.3950229158401489; test_loss=0.38735888481140135\n",
      "save model\n",
      "epoch = 32; train_loss = 0.3487801856994629; test_loss=0.342634961605072\n",
      "save model\n",
      "epoch = 33; train_loss = 0.31108750808238983; test_loss=0.30807423651218413\n",
      "save model\n",
      "epoch = 34; train_loss = 0.2833253836631775; test_loss=0.29158683240413663\n",
      "save model\n",
      "epoch = 35; train_loss = 0.26545976746082306; test_loss=0.2660326260328293\n",
      "save model\n",
      "epoch = 36; train_loss = 0.24615139257907867; test_loss=0.25904631316661836\n",
      "save model\n",
      "epoch = 37; train_loss = 0.22958790385723113; test_loss=0.23817770957946777\n",
      "save model\n",
      "epoch = 38; train_loss = 0.2143558986186981; test_loss=0.21586028218269349\n",
      "save model\n",
      "epoch = 39; train_loss = 0.20452516961097716; test_loss=0.2280013620853424\n",
      "save model\n",
      "epoch = 40; train_loss = 0.1977281826734543; test_loss=0.20431629300117493\n",
      "save model\n",
      "epoch = 41; train_loss = 0.18762065839767456; test_loss=0.18734017372131348\n",
      "save model\n",
      "epoch = 42; train_loss = 0.1807578935623169; test_loss=0.1817879295349121\n",
      "save model\n",
      "epoch = 43; train_loss = 0.17322823333740234; test_loss=0.19716882705688477\n",
      "save model\n",
      "epoch = 44; train_loss = 0.16622543382644653; test_loss=0.17431430339813234\n",
      "save model\n",
      "epoch = 45; train_loss = 0.1627098650932312; test_loss=0.1672345244884491\n",
      "save model\n",
      "epoch = 46; train_loss = 0.1622145621776581; test_loss=0.1865196132659912\n",
      "save model\n",
      "epoch = 47; train_loss = 0.15740689420700074; test_loss=0.16006333589553834\n",
      "save model\n",
      "epoch = 48; train_loss = 0.14391256546974182; test_loss=0.165431666970253\n",
      "save model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 49; train_loss = 0.1456159714460373; test_loss=0.1639876753091812\n",
      "torus1 0.1 ----------------------------------------------------------------------------------------------------\n",
      "epoch = 0; train_loss = 58.186902801513675; test_loss=45.52058959960937\n",
      "save model\n",
      "epoch = 1; train_loss = 40.33847360229492; test_loss=31.802446212768555\n",
      "save model\n",
      "epoch = 2; train_loss = 28.52710870361328; test_loss=23.3787060546875\n",
      "save model\n",
      "epoch = 3; train_loss = 20.637112152099608; test_loss=15.216281356811523\n",
      "save model\n",
      "epoch = 4; train_loss = 12.771727569580078; test_loss=9.273172073364258\n",
      "save model\n",
      "epoch = 5; train_loss = 7.243203647613526; test_loss=4.767129859924316\n",
      "save model\n",
      "epoch = 6; train_loss = 3.8184190101623536; test_loss=2.719597158432007\n",
      "save model\n",
      "epoch = 7; train_loss = 2.615072235107422; test_loss=2.284588499069214\n",
      "save model\n",
      "epoch = 8; train_loss = 2.413914192199707; test_loss=2.1121665477752685\n",
      "save model\n",
      "epoch = 9; train_loss = 2.1609542236328125; test_loss=2.0554979610443116\n",
      "save model\n",
      "epoch = 10; train_loss = 2.4537349815368654; test_loss=2.094513425827026\n",
      "epoch = 11; train_loss = 2.4147087955474853; test_loss=2.350936117172241\n",
      "epoch = 12; train_loss = 2.264981107711792; test_loss=2.044111409187317\n",
      "epoch = 13; train_loss = 2.0553031902313235; test_loss=1.9410466051101685\n",
      "save model\n",
      "epoch = 14; train_loss = 1.9879329414367677; test_loss=1.8757431173324586\n",
      "save model\n",
      "epoch = 15; train_loss = 1.8931166458129882; test_loss=1.8532944059371947\n",
      "save model\n",
      "epoch = 16; train_loss = 1.8706069793701172; test_loss=2.036325006484985\n",
      "save model\n",
      "epoch = 17; train_loss = 1.9259449729919433; test_loss=1.8599658203125\n",
      "epoch = 18; train_loss = 1.803738618850708; test_loss=1.9441546249389647\n",
      "save model\n",
      "epoch = 19; train_loss = 1.9461305017471313; test_loss=1.7741264581680298\n",
      "epoch = 20; train_loss = 1.9069549465179443; test_loss=1.80227566242218\n",
      "epoch = 21; train_loss = 1.7413184719085693; test_loss=1.89785653591156\n",
      "save model\n",
      "epoch = 22; train_loss = 1.864539665222168; test_loss=1.7444192838668824\n",
      "epoch = 23; train_loss = 1.6207244701385497; test_loss=1.7286311435699462\n",
      "save model\n",
      "epoch = 24; train_loss = 1.6472506914138794; test_loss=1.7474760484695435\n",
      "epoch = 25; train_loss = 1.5911775751113892; test_loss=1.6279525136947632\n",
      "save model\n",
      "epoch = 26; train_loss = 1.5402266445159911; test_loss=1.6526543378829956\n",
      "save model\n",
      "epoch = 27; train_loss = 1.4552213096618651; test_loss=1.5512052488327026\n",
      "save model\n",
      "epoch = 28; train_loss = 1.4722933568954468; test_loss=1.583466763496399\n",
      "epoch = 29; train_loss = 1.4119609622955323; test_loss=1.571031503677368\n",
      "save model\n",
      "epoch = 30; train_loss = 1.3667060527801513; test_loss=1.5704925489425658\n",
      "save model\n",
      "epoch = 31; train_loss = 1.4211926946640014; test_loss=1.5850231456756592\n",
      "epoch = 32; train_loss = 1.3384956693649293; test_loss=1.579328680038452\n",
      "save model\n",
      "epoch = 33; train_loss = 1.3603259534835817; test_loss=1.5765751266479493\n",
      "epoch = 34; train_loss = 1.3192913599014282; test_loss=1.5686617660522462\n",
      "save model\n",
      "epoch = 35; train_loss = 1.3326126260757447; test_loss=1.6093067026138306\n",
      "epoch = 36; train_loss = 1.236638011932373; test_loss=1.5675285243988037\n",
      "save model\n",
      "epoch = 37; train_loss = 1.2010886154174805; test_loss=1.5065709972381591\n",
      "save model\n",
      "epoch = 38; train_loss = 1.2237119169235229; test_loss=1.5873729515075683\n",
      "epoch = 39; train_loss = 1.2307703027725219; test_loss=1.6186684656143189\n",
      "epoch = 40; train_loss = 1.2255123510360717; test_loss=1.6204099369049072\n",
      "epoch = 41; train_loss = 1.170023868560791; test_loss=1.6292390489578248\n",
      "save model\n",
      "epoch = 42; train_loss = 1.2518643336296083; test_loss=1.4966707277297973\n",
      "epoch = 43; train_loss = 1.1705778913497924; test_loss=1.6342396688461305\n",
      "epoch = 44; train_loss = 1.132191640853882; test_loss=1.562016749382019\n",
      "save model\n",
      "epoch = 45; train_loss = 1.186391100883484; test_loss=1.6100415945053101\n",
      "epoch = 46; train_loss = 1.1827362084388733; test_loss=1.6034331655502319\n",
      "epoch = 47; train_loss = 1.1978197894096374; test_loss=1.5235031700134278\n",
      "epoch = 48; train_loss = 1.073611610889435; test_loss=1.5708533906936646\n",
      "save model\n",
      "epoch = 49; train_loss = 1.0569430150985717; test_loss=1.5850361204147339\n",
      "save model\n",
      "epoch = 0; train_loss = 187.5838186645508; test_loss=184.0872332763672\n",
      "save model\n",
      "epoch = 1; train_loss = 158.02589868164063; test_loss=156.7441278076172\n",
      "save model\n",
      "epoch = 2; train_loss = 132.1493784790039; test_loss=128.41370849609376\n",
      "save model\n",
      "epoch = 3; train_loss = 108.2462275390625; test_loss=106.01340270996094\n",
      "save model\n",
      "epoch = 4; train_loss = 88.95187142944336; test_loss=86.76790466308594\n",
      "save model\n",
      "epoch = 5; train_loss = 72.06042282104492; test_loss=69.51189147949219\n",
      "save model\n",
      "epoch = 6; train_loss = 57.01542175292969; test_loss=54.56269149780273\n",
      "save model\n",
      "epoch = 7; train_loss = 44.164030975341795; test_loss=41.72417434692383\n",
      "save model\n",
      "epoch = 8; train_loss = 33.33559973144531; test_loss=31.01484100341797\n",
      "save model\n",
      "epoch = 9; train_loss = 24.309623878479005; test_loss=22.19452392578125\n",
      "save model\n",
      "epoch = 10; train_loss = 17.034114482879637; test_loss=15.13518035888672\n",
      "save model\n",
      "epoch = 11; train_loss = 11.305419158935546; test_loss=9.673404998779297\n",
      "save model\n",
      "epoch = 12; train_loss = 6.983637979507447; test_loss=5.650805263519287\n",
      "save model\n",
      "epoch = 13; train_loss = 3.949153800010681; test_loss=3.0127607440948485\n",
      "save model\n",
      "epoch = 14; train_loss = 2.0717508745193483; test_loss=1.5601763248443603\n",
      "save model\n",
      "epoch = 15; train_loss = 1.1282518572807312; test_loss=0.9037023496627807\n",
      "save model\n",
      "epoch = 16; train_loss = 0.7130079164505004; test_loss=0.6110755133628846\n",
      "save model\n",
      "epoch = 17; train_loss = 0.514383547782898; test_loss=0.4598772609233856\n",
      "save model\n",
      "epoch = 18; train_loss = 0.4033178749084473; test_loss=0.37485366702079775\n",
      "save model\n",
      "epoch = 19; train_loss = 0.3379075071811676; test_loss=0.32392266631126404\n",
      "save model\n",
      "epoch = 20; train_loss = 0.2984800844192505; test_loss=0.2911786234378815\n",
      "save model\n",
      "epoch = 21; train_loss = 0.2678554947376251; test_loss=0.27064887166023255\n",
      "save model\n",
      "epoch = 22; train_loss = 0.24519548416137696; test_loss=0.25438773989677427\n",
      "save model\n",
      "epoch = 23; train_loss = 0.22805378651618957; test_loss=0.2401347863674164\n",
      "save model\n",
      "epoch = 24; train_loss = 0.214905592918396; test_loss=0.22974120438098908\n",
      "save model\n",
      "epoch = 25; train_loss = 0.20421711659431457; test_loss=0.22622957527637483\n",
      "save model\n",
      "epoch = 26; train_loss = 0.19602072763442993; test_loss=0.22320399105548858\n",
      "save model\n",
      "epoch = 27; train_loss = 0.187305095911026; test_loss=0.21164757490158081\n",
      "save model\n",
      "epoch = 28; train_loss = 0.19020625460147858; test_loss=0.1961498302221298\n",
      "epoch = 29; train_loss = 0.17131726586818696; test_loss=0.19228322744369508\n",
      "save model\n",
      "epoch = 30; train_loss = 0.16754876458644866; test_loss=0.1966416656970978\n",
      "save model\n",
      "epoch = 31; train_loss = 0.16599674463272096; test_loss=0.18194696605205535\n",
      "save model\n",
      "epoch = 32; train_loss = 0.15872082364559173; test_loss=0.17822572648525237\n",
      "save model\n",
      "epoch = 33; train_loss = 0.15458286321163178; test_loss=0.17784085512161255\n",
      "save model\n",
      "epoch = 34; train_loss = 0.15164858543872833; test_loss=0.17759202897548676\n",
      "save model\n",
      "epoch = 35; train_loss = 0.14622637271881103; test_loss=0.17587486386299134\n",
      "save model\n",
      "epoch = 36; train_loss = 0.14248396861553192; test_loss=0.1735852414369583\n",
      "save model\n",
      "epoch = 37; train_loss = 0.140656107544899; test_loss=0.1676705777645111\n",
      "save model\n",
      "epoch = 38; train_loss = 0.13896880257129668; test_loss=0.17010154724121093\n",
      "save model\n",
      "epoch = 39; train_loss = 0.136731707572937; test_loss=0.16539854019880296\n",
      "save model\n",
      "epoch = 40; train_loss = 0.1360384339094162; test_loss=0.16563713073730468\n",
      "save model\n",
      "epoch = 41; train_loss = 0.13075882613658904; test_loss=0.15816425770521164\n",
      "save model\n",
      "epoch = 42; train_loss = 0.1316372821331024; test_loss=0.16684304893016816\n",
      "epoch = 43; train_loss = 0.12910733318328857; test_loss=0.166715829372406\n",
      "save model\n",
      "epoch = 44; train_loss = 0.12598451793193818; test_loss=0.1604464292526245\n",
      "save model\n",
      "epoch = 45; train_loss = 0.1187656751871109; test_loss=0.15792366683483125\n",
      "save model\n",
      "epoch = 46; train_loss = 0.11939123129844666; test_loss=0.15448192536830901\n",
      "epoch = 47; train_loss = 0.12011943221092224; test_loss=0.15863498747348787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 48; train_loss = 0.11826732945442199; test_loss=0.15481894493103027\n",
      "save model\n",
      "epoch = 49; train_loss = 0.11300837290287018; test_loss=0.15728315383195876\n",
      "save model\n",
      "torus1 0.5 ----------------------------------------------------------------------------------------------------\n",
      "epoch = 0; train_loss = 59.98885037231445; test_loss=51.86405166625977\n",
      "save model\n",
      "epoch = 1; train_loss = 41.67302020263672; test_loss=36.27059799194336\n",
      "save model\n",
      "epoch = 2; train_loss = 29.373047897338868; test_loss=26.043401184082033\n",
      "save model\n",
      "epoch = 3; train_loss = 20.90655107116699; test_loss=17.194327583312987\n",
      "save model\n",
      "epoch = 4; train_loss = 13.346044746398926; test_loss=10.586718406677246\n",
      "save model\n",
      "epoch = 5; train_loss = 7.546941207885742; test_loss=5.351316251754761\n",
      "save model\n",
      "epoch = 6; train_loss = 3.88597598361969; test_loss=3.0585909414291383\n",
      "save model\n",
      "epoch = 7; train_loss = 2.729946400642395; test_loss=2.5670898389816283\n",
      "save model\n",
      "epoch = 8; train_loss = 2.4348588581085204; test_loss=2.4260773134231566\n",
      "save model\n",
      "epoch = 9; train_loss = 2.3112417974472046; test_loss=2.3152232217788695\n",
      "save model\n",
      "epoch = 10; train_loss = 2.7440587749481202; test_loss=2.324895153045654\n",
      "epoch = 11; train_loss = 2.1777989492416383; test_loss=2.1976887226104735\n",
      "save model\n",
      "epoch = 12; train_loss = 2.2458318700790407; test_loss=2.3467014265060424\n",
      "epoch = 13; train_loss = 2.166210536003113; test_loss=2.1864744424819946\n",
      "save model\n",
      "epoch = 14; train_loss = 2.0548724813461305; test_loss=2.1287890911102294\n",
      "save model\n",
      "epoch = 15; train_loss = 1.9948763236999512; test_loss=2.059786295890808\n",
      "save model\n",
      "epoch = 16; train_loss = 1.9914182081222533; test_loss=2.1013793182373046\n",
      "save model\n",
      "epoch = 17; train_loss = 1.9473958320617675; test_loss=2.058645181655884\n",
      "save model\n",
      "epoch = 18; train_loss = 1.9477379455566406; test_loss=2.0703369188308716\n",
      "epoch = 19; train_loss = 1.9390081200599671; test_loss=2.0264140605926513\n",
      "save model\n",
      "epoch = 20; train_loss = 1.912921980857849; test_loss=2.1332769632339477\n",
      "save model\n",
      "epoch = 21; train_loss = 1.8988801922798157; test_loss=1.9970829343795777\n",
      "save model\n",
      "epoch = 22; train_loss = 1.9615160923004151; test_loss=2.013741054534912\n",
      "epoch = 23; train_loss = 1.8460411415100098; test_loss=2.0205157136917116\n",
      "save model\n",
      "epoch = 24; train_loss = 1.8185416116714477; test_loss=1.9831257724761964\n",
      "save model\n",
      "epoch = 25; train_loss = 1.8265604395866395; test_loss=1.9606873655319215\n",
      "epoch = 26; train_loss = 1.774027940750122; test_loss=1.9641425943374633\n",
      "save model\n",
      "epoch = 27; train_loss = 1.7761747074127197; test_loss=1.9505257177352906\n",
      "epoch = 28; train_loss = 1.7566551723480224; test_loss=1.9486532783508301\n",
      "save model\n",
      "epoch = 29; train_loss = 1.7262505130767822; test_loss=1.8884882640838623\n",
      "save model\n",
      "epoch = 30; train_loss = 1.7995489625930785; test_loss=2.00990375995636\n",
      "epoch = 31; train_loss = 1.7610296392440796; test_loss=1.916981816291809\n",
      "epoch = 32; train_loss = 1.6750143842697143; test_loss=1.9859961414337157\n",
      "save model\n",
      "epoch = 33; train_loss = 1.6773967471122742; test_loss=1.904853434562683\n",
      "epoch = 34; train_loss = 1.6628061394691467; test_loss=1.987464838027954\n",
      "save model\n",
      "epoch = 35; train_loss = 1.6842564902305603; test_loss=1.915636076927185\n",
      "epoch = 36; train_loss = 1.6284820003509521; test_loss=1.9256088495254517\n",
      "save model\n",
      "epoch = 37; train_loss = 1.6216121883392334; test_loss=1.9163778877258302\n",
      "save model\n",
      "epoch = 38; train_loss = 1.5987139711380005; test_loss=1.8944424819946288\n",
      "save model\n",
      "epoch = 39; train_loss = 1.6163144969940186; test_loss=1.9617767477035521\n",
      "epoch = 40; train_loss = 1.6172406616210937; test_loss=2.118886570930481\n",
      "epoch = 41; train_loss = 1.6218007073402405; test_loss=1.9189103841781616\n",
      "epoch = 42; train_loss = 1.5549877490997315; test_loss=1.9376978015899657\n",
      "save model\n",
      "epoch = 43; train_loss = 1.5498594522476197; test_loss=1.884271306991577\n",
      "save model\n",
      "epoch = 44; train_loss = 1.4985524797439576; test_loss=1.8817999124526978\n",
      "save model\n",
      "epoch = 45; train_loss = 1.516181622505188; test_loss=1.8903131914138793\n",
      "epoch = 46; train_loss = 1.4834754943847657; test_loss=1.905086064338684\n",
      "save model\n",
      "epoch = 47; train_loss = 1.459138074874878; test_loss=1.9310455989837647\n",
      "save model\n",
      "epoch = 48; train_loss = 1.5008761582374572; test_loss=1.8903687286376953\n",
      "epoch = 49; train_loss = 1.465946665763855; test_loss=1.9574063682556153\n",
      "epoch = 0; train_loss = 175.40837426757813; test_loss=149.80411529541016\n",
      "save model\n",
      "epoch = 1; train_loss = 147.58203552246093; test_loss=126.95635955810548\n",
      "save model\n",
      "epoch = 2; train_loss = 125.34674426269531; test_loss=103.96003448486329\n",
      "save model\n",
      "epoch = 3; train_loss = 100.78687005615234; test_loss=84.23386657714843\n",
      "save model\n",
      "epoch = 4; train_loss = 82.35123248291016; test_loss=68.64960525512696\n",
      "save model\n",
      "epoch = 5; train_loss = 66.56883966064453; test_loss=54.42893783569336\n",
      "save model\n",
      "epoch = 6; train_loss = 52.42409625244141; test_loss=42.30647743225098\n",
      "save model\n",
      "epoch = 7; train_loss = 40.401255889892575; test_loss=32.08046211242676\n",
      "save model\n",
      "epoch = 8; train_loss = 30.31812861633301; test_loss=23.659949378967283\n",
      "save model\n",
      "epoch = 9; train_loss = 22.091975509643554; test_loss=16.85613395690918\n",
      "save model\n",
      "epoch = 10; train_loss = 15.474218284606934; test_loss=11.490917568206788\n",
      "save model\n",
      "epoch = 11; train_loss = 10.308413982391357; test_loss=7.418520803451538\n",
      "save model\n",
      "epoch = 12; train_loss = 6.457186252593994; test_loss=4.4678905487060545\n",
      "save model\n",
      "epoch = 13; train_loss = 3.7557745189666747; test_loss=2.496438865661621\n",
      "save model\n",
      "epoch = 14; train_loss = 2.060487424850464; test_loss=1.3805211782455444\n",
      "save model\n",
      "epoch = 15; train_loss = 1.172842059135437; test_loss=0.8484717059135437\n",
      "save model\n",
      "epoch = 16; train_loss = 0.7504475483894348; test_loss=0.5951215219497681\n",
      "save model\n",
      "epoch = 17; train_loss = 0.5479222364425659; test_loss=0.4690368103981018\n",
      "save model\n",
      "epoch = 18; train_loss = 0.4311127598285675; test_loss=0.3996454119682312\n",
      "save model\n",
      "epoch = 19; train_loss = 0.3608926558494568; test_loss=0.34728975415229796\n",
      "save model\n",
      "epoch = 20; train_loss = 0.3139804046154022; test_loss=0.31516914010047914\n",
      "save model\n",
      "epoch = 21; train_loss = 0.28246540427207945; test_loss=0.2921753454208374\n",
      "save model\n",
      "epoch = 22; train_loss = 0.26249224197864535; test_loss=0.2726797527074814\n",
      "save model\n",
      "epoch = 23; train_loss = 0.24377912878990174; test_loss=0.2582613635063171\n",
      "save model\n",
      "epoch = 24; train_loss = 0.23097991144657135; test_loss=0.24482368648052216\n",
      "save model\n",
      "epoch = 25; train_loss = 0.21824098217487337; test_loss=0.2332954466342926\n",
      "save model\n",
      "epoch = 26; train_loss = 0.20757507252693178; test_loss=0.22847002625465393\n",
      "save model\n",
      "epoch = 27; train_loss = 0.2002244244813919; test_loss=0.2280090045928955\n",
      "save model\n",
      "epoch = 28; train_loss = 0.1930524561405182; test_loss=0.22339946866035462\n",
      "save model\n",
      "epoch = 29; train_loss = 0.18713641929626465; test_loss=0.21726650774478912\n",
      "save model\n",
      "epoch = 30; train_loss = 0.18388309997320176; test_loss=0.2147596788406372\n",
      "save model\n",
      "epoch = 31; train_loss = 0.1772283947467804; test_loss=0.21202864944934846\n",
      "save model\n",
      "epoch = 32; train_loss = 0.17109229397773743; test_loss=0.2033841222524643\n",
      "save model\n",
      "epoch = 33; train_loss = 0.16935126447677612; test_loss=0.2035751622915268\n",
      "save model\n",
      "epoch = 34; train_loss = 0.16613363867998124; test_loss=0.1952441143989563\n",
      "save model\n",
      "epoch = 35; train_loss = 0.1615666931271553; test_loss=0.19773414492607116\n",
      "save model\n",
      "epoch = 36; train_loss = 0.15991039389371872; test_loss=0.18924980342388154\n",
      "save model\n",
      "epoch = 37; train_loss = 0.1554560084939003; test_loss=0.18499234676361084\n",
      "save model\n",
      "epoch = 38; train_loss = 0.14891782212257385; test_loss=0.19254444062709808\n",
      "save model\n",
      "epoch = 39; train_loss = 0.15424022954702377; test_loss=0.18469124794006347\n",
      "epoch = 40; train_loss = 0.14619744580984115; test_loss=0.18858353912830353\n",
      "save model\n",
      "epoch = 41; train_loss = 0.14606183177232743; test_loss=0.18057302713394166\n",
      "save model\n",
      "epoch = 42; train_loss = 0.14613583528995513; test_loss=0.18436664283275606\n",
      "epoch = 43; train_loss = 0.14429911404848098; test_loss=0.17929257810115815\n",
      "save model\n",
      "epoch = 44; train_loss = 0.14096360915899278; test_loss=0.17527144610881806\n",
      "save model\n",
      "epoch = 45; train_loss = 0.1359001406431198; test_loss=0.17112066745758056\n",
      "save model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 46; train_loss = 0.13763370537757874; test_loss=0.18007359862327577\n",
      "epoch = 47; train_loss = 0.13806975346803665; test_loss=0.17531623661518098\n",
      "epoch = 48; train_loss = 0.13402389669418335; test_loss=0.17373304009437562\n",
      "save model\n",
      "epoch = 49; train_loss = 0.13062801629304885; test_loss=0.1693816041946411\n",
      "save model\n",
      "torus2 0.1 ----------------------------------------------------------------------------------------------------\n",
      "epoch = 0; train_loss = 61.062154083251954; test_loss=51.32860229492187\n",
      "save model\n",
      "epoch = 1; train_loss = 42.467556030273435; test_loss=35.85173034667969\n",
      "save model\n",
      "epoch = 2; train_loss = 29.940530319213867; test_loss=25.656807861328126\n",
      "save model\n",
      "epoch = 3; train_loss = 21.59395248413086; test_loss=17.173040084838867\n",
      "save model\n",
      "epoch = 4; train_loss = 13.76871469116211; test_loss=10.94708335876465\n",
      "save model\n",
      "epoch = 5; train_loss = 8.064839023590087; test_loss=5.443332653045655\n",
      "save model\n",
      "epoch = 6; train_loss = 3.8620230712890624; test_loss=2.7680653858184816\n",
      "save model\n",
      "epoch = 7; train_loss = 2.527071096420288; test_loss=2.177802095413208\n",
      "save model\n",
      "epoch = 8; train_loss = 2.5096660690307617; test_loss=2.6285268211364747\n",
      "save model\n",
      "epoch = 9; train_loss = 2.1752167720794677; test_loss=1.976192398071289\n",
      "save model\n",
      "epoch = 10; train_loss = 1.9762037830352783; test_loss=1.8899966144561768\n",
      "save model\n",
      "epoch = 11; train_loss = 1.8657572565078735; test_loss=1.8413825035095215\n",
      "save model\n",
      "epoch = 12; train_loss = 1.875916591644287; test_loss=1.894092445373535\n",
      "epoch = 13; train_loss = 1.8663525485992432; test_loss=1.807922420501709\n",
      "epoch = 14; train_loss = 1.7450344982147217; test_loss=1.7319021606445313\n",
      "save model\n",
      "epoch = 15; train_loss = 1.6926350631713867; test_loss=1.7073889541625977\n",
      "save model\n",
      "epoch = 16; train_loss = 1.6280591468811034; test_loss=1.6857708168029786\n",
      "save model\n",
      "epoch = 17; train_loss = 1.6014400777816773; test_loss=1.6753871250152588\n",
      "save model\n",
      "epoch = 18; train_loss = 1.635058316230774; test_loss=1.6497182941436768\n",
      "epoch = 19; train_loss = 1.5446694831848145; test_loss=1.6785976028442382\n",
      "save model\n",
      "epoch = 20; train_loss = 1.586173342704773; test_loss=1.612383451461792\n",
      "epoch = 21; train_loss = 1.7670360193252563; test_loss=1.7483936309814454\n",
      "epoch = 22; train_loss = 1.534339864730835; test_loss=1.608293228149414\n",
      "save model\n",
      "epoch = 23; train_loss = 1.4787005662918091; test_loss=1.575949831008911\n",
      "save model\n",
      "epoch = 24; train_loss = 1.5224795331954957; test_loss=1.5844344902038574\n",
      "epoch = 25; train_loss = 1.4143687314987183; test_loss=1.5877578830718995\n",
      "save model\n",
      "epoch = 26; train_loss = 1.430347864151001; test_loss=1.6355218410491943\n",
      "epoch = 27; train_loss = 1.3865212678909302; test_loss=1.62321213722229\n",
      "save model\n",
      "epoch = 28; train_loss = 1.3382673873901367; test_loss=1.5263909196853638\n",
      "save model\n",
      "epoch = 29; train_loss = 1.316511721611023; test_loss=1.6069859313964843\n",
      "save model\n",
      "epoch = 30; train_loss = 1.3088721885681152; test_loss=1.527855224609375\n",
      "save model\n",
      "epoch = 31; train_loss = 1.3877139797210694; test_loss=1.5429112148284911\n",
      "epoch = 32; train_loss = 1.3330413370132446; test_loss=1.6918072605133057\n",
      "epoch = 33; train_loss = 1.3152843732833863; test_loss=1.5327614641189575\n",
      "epoch = 34; train_loss = 1.2556093549728393; test_loss=1.5684940242767333\n",
      "save model\n",
      "epoch = 35; train_loss = 1.3234500074386597; test_loss=1.5083005332946777\n",
      "epoch = 36; train_loss = 1.231409665107727; test_loss=1.607760901451111\n",
      "save model\n",
      "epoch = 37; train_loss = 1.260819065093994; test_loss=1.5781863689422608\n",
      "epoch = 38; train_loss = 1.2247538347244262; test_loss=1.565153522491455\n",
      "save model\n",
      "epoch = 39; train_loss = 1.3101732692718506; test_loss=1.6439256858825684\n",
      "epoch = 40; train_loss = 1.2687424392700195; test_loss=1.5337977933883666\n",
      "epoch = 41; train_loss = 1.1632685561180114; test_loss=1.5616186332702637\n",
      "save model\n",
      "epoch = 42; train_loss = 1.1867520122528077; test_loss=1.5564830255508424\n",
      "epoch = 43; train_loss = 1.212574137687683; test_loss=1.5578359365463257\n",
      "epoch = 44; train_loss = 1.1260030822753906; test_loss=1.592514214515686\n",
      "save model\n",
      "epoch = 45; train_loss = 1.0660683932304382; test_loss=1.6256486129760743\n",
      "save model\n",
      "epoch = 46; train_loss = 1.1782420663833617; test_loss=1.5473099946975708\n",
      "epoch = 47; train_loss = 1.0649153084754943; test_loss=1.6047750663757325\n",
      "save model\n",
      "epoch = 48; train_loss = 1.0946791973114014; test_loss=1.5469750547409058\n",
      "epoch = 49; train_loss = 1.025595516681671; test_loss=1.6222345733642578\n",
      "save model\n",
      "epoch = 0; train_loss = 280.47679907226564; test_loss=249.54097778320312\n",
      "save model\n",
      "epoch = 1; train_loss = 248.30210388183593; test_loss=222.47930786132812\n",
      "save model\n",
      "epoch = 2; train_loss = 220.38933361816407; test_loss=193.75367736816406\n",
      "save model\n",
      "epoch = 3; train_loss = 191.6901728515625; test_loss=170.2883166503906\n",
      "save model\n",
      "epoch = 4; train_loss = 168.39707934570313; test_loss=149.46131896972656\n",
      "save model\n",
      "epoch = 5; train_loss = 147.3466917114258; test_loss=130.18700408935547\n",
      "save model\n",
      "epoch = 6; train_loss = 127.95757806396485; test_loss=112.74731750488282\n",
      "save model\n",
      "epoch = 7; train_loss = 110.57577996826171; test_loss=97.26307037353516\n",
      "save model\n",
      "epoch = 8; train_loss = 95.03254431152344; test_loss=83.3032095336914\n",
      "save model\n",
      "epoch = 9; train_loss = 81.09852032470702; test_loss=70.86151123046875\n",
      "save model\n",
      "epoch = 10; train_loss = 68.70531253051757; test_loss=59.818583984375\n",
      "save model\n",
      "epoch = 11; train_loss = 57.714993545532224; test_loss=50.08080001831055\n",
      "save model\n",
      "epoch = 12; train_loss = 48.05499195861817; test_loss=41.5149169921875\n",
      "save model\n",
      "epoch = 13; train_loss = 39.5972566986084; test_loss=34.06346939086914\n",
      "save model\n",
      "epoch = 14; train_loss = 32.27885998535156; test_loss=27.617024383544923\n",
      "save model\n",
      "epoch = 15; train_loss = 25.95429421234131; test_loss=22.086310348510743\n",
      "save model\n",
      "epoch = 16; train_loss = 20.57104221343994; test_loss=17.39093200683594\n",
      "save model\n",
      "epoch = 17; train_loss = 16.041523811340333; test_loss=13.49851577758789\n",
      "save model\n",
      "epoch = 18; train_loss = 12.309586582183838; test_loss=10.293410377502441\n",
      "save model\n",
      "epoch = 19; train_loss = 9.255527568817138; test_loss=7.663157062530518\n",
      "save model\n",
      "epoch = 20; train_loss = 6.833093564987182; test_loss=5.6303933906555175\n",
      "save model\n",
      "epoch = 21; train_loss = 4.983396570205689; test_loss=4.094880666732788\n",
      "save model\n",
      "epoch = 22; train_loss = 3.625234342575073; test_loss=2.9992844390869142\n",
      "save model\n",
      "epoch = 23; train_loss = 2.6692304515838625; test_loss=2.2391132354736327\n",
      "save model\n",
      "epoch = 24; train_loss = 2.013374161720276; test_loss=1.7194996500015258\n",
      "save model\n",
      "epoch = 25; train_loss = 1.5609488410949708; test_loss=1.3683204221725465\n",
      "save model\n",
      "epoch = 26; train_loss = 1.241400975227356; test_loss=1.0989367294311523\n",
      "save model\n",
      "epoch = 27; train_loss = 1.0076545543670654; test_loss=0.9013045501708984\n",
      "save model\n",
      "epoch = 28; train_loss = 0.8329439373016357; test_loss=0.7543492269515991\n",
      "save model\n",
      "epoch = 29; train_loss = 0.702130823135376; test_loss=0.6450851559638977\n",
      "save model\n",
      "epoch = 30; train_loss = 0.6014014229774475; test_loss=0.5582522130012513\n",
      "save model\n",
      "epoch = 31; train_loss = 0.5215323081016541; test_loss=0.49196921348571776\n",
      "save model\n",
      "epoch = 32; train_loss = 0.4598954153060913; test_loss=0.439917334318161\n",
      "save model\n",
      "epoch = 33; train_loss = 0.41307051753997803; test_loss=0.3933699607849121\n",
      "save model\n",
      "epoch = 34; train_loss = 0.3684958984851837; test_loss=0.3630824863910675\n",
      "save model\n",
      "epoch = 35; train_loss = 0.3382615306377411; test_loss=0.32771570444107057\n",
      "save model\n",
      "epoch = 36; train_loss = 0.3073531017303467; test_loss=0.3107625412940979\n",
      "save model\n",
      "epoch = 37; train_loss = 0.28969032859802246; test_loss=0.2948304831981659\n",
      "save model\n",
      "epoch = 38; train_loss = 0.26349961280822753; test_loss=0.2766247451305389\n",
      "save model\n",
      "epoch = 39; train_loss = 0.2536808152198792; test_loss=0.2632827150821686\n",
      "save model\n",
      "epoch = 40; train_loss = 0.23983836662769317; test_loss=0.24023452043533325\n",
      "save model\n",
      "epoch = 41; train_loss = 0.2267670489549637; test_loss=0.23491585731506348\n",
      "save model\n",
      "epoch = 42; train_loss = 0.21646484339237212; test_loss=0.24236122250556946\n",
      "save model\n",
      "epoch = 43; train_loss = 0.21202589535713195; test_loss=0.2271745854616165\n",
      "save model\n",
      "epoch = 44; train_loss = 0.20078442895412446; test_loss=0.2339206373691559\n",
      "save model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 45; train_loss = 0.20362141239643097; test_loss=0.21606138706207276\n",
      "epoch = 46; train_loss = 0.19329860317707062; test_loss=0.21297238051891326\n",
      "save model\n",
      "epoch = 47; train_loss = 0.18091903150081634; test_loss=0.19220730125904084\n",
      "save model\n",
      "epoch = 48; train_loss = 0.17405987334251405; test_loss=0.19708967506885527\n",
      "save model\n",
      "epoch = 49; train_loss = 0.16984657239913942; test_loss=0.19005816102027892\n",
      "save model\n",
      "torus2 0.5 ----------------------------------------------------------------------------------------------------\n",
      "epoch = 0; train_loss = 62.523958190917966; test_loss=51.53033554077148\n",
      "save model\n",
      "epoch = 1; train_loss = 43.5497818145752; test_loss=36.00705307006836\n",
      "save model\n",
      "epoch = 2; train_loss = 30.644112884521483; test_loss=25.77215835571289\n",
      "save model\n",
      "epoch = 3; train_loss = 22.214628662109376; test_loss=17.212132568359376\n",
      "save model\n",
      "epoch = 4; train_loss = 14.210256633758545; test_loss=10.68941749572754\n",
      "save model\n",
      "epoch = 5; train_loss = 7.977547040939331; test_loss=5.373474006652832\n",
      "save model\n",
      "epoch = 6; train_loss = 4.006595190048218; test_loss=2.944745807647705\n",
      "save model\n",
      "epoch = 7; train_loss = 2.720593336582184; test_loss=2.4652887916564943\n",
      "save model\n",
      "epoch = 8; train_loss = 2.409321885585785; test_loss=2.3119326782226564\n",
      "save model\n",
      "epoch = 9; train_loss = 2.37914187669754; test_loss=2.2598710918426512\n",
      "save model\n",
      "epoch = 10; train_loss = 2.2096159706115723; test_loss=2.19098032951355\n",
      "save model\n",
      "epoch = 11; train_loss = 2.1602520513534547; test_loss=2.157237243652344\n",
      "save model\n",
      "epoch = 12; train_loss = 2.1092444224357605; test_loss=2.112692518234253\n",
      "save model\n",
      "epoch = 13; train_loss = 2.0724509797096253; test_loss=2.156060037612915\n",
      "save model\n",
      "epoch = 14; train_loss = 2.09471160030365; test_loss=2.2685831642150878\n",
      "epoch = 15; train_loss = 2.0580300092697144; test_loss=2.0733894538879394\n",
      "save model\n",
      "epoch = 16; train_loss = 1.9725707569122315; test_loss=2.027997121810913\n",
      "save model\n",
      "epoch = 17; train_loss = 1.957383936882019; test_loss=2.095152645111084\n",
      "save model\n",
      "epoch = 18; train_loss = 1.9362867479324342; test_loss=2.040213747024536\n",
      "save model\n",
      "epoch = 19; train_loss = 1.887386897087097; test_loss=1.9970042848587035\n",
      "save model\n",
      "epoch = 20; train_loss = 1.8481235241889953; test_loss=2.0014239072799684\n",
      "save model\n",
      "epoch = 21; train_loss = 1.8511428236961365; test_loss=1.9736121082305909\n",
      "epoch = 22; train_loss = 1.8639314870834351; test_loss=2.111953716278076\n",
      "epoch = 23; train_loss = 1.8320656485557556; test_loss=1.977140679359436\n",
      "save model\n",
      "epoch = 24; train_loss = 1.7804947319030762; test_loss=1.942857151031494\n",
      "save model\n",
      "epoch = 25; train_loss = 1.7097295031547546; test_loss=1.9205361795425415\n",
      "save model\n",
      "epoch = 26; train_loss = 1.7251948094367981; test_loss=1.923951768875122\n",
      "epoch = 27; train_loss = 1.7239954996109008; test_loss=1.9672639083862304\n",
      "epoch = 28; train_loss = 1.6963463106155396; test_loss=1.9756485366821288\n",
      "save model\n",
      "epoch = 29; train_loss = 1.7226260690689086; test_loss=1.932630681991577\n",
      "epoch = 30; train_loss = 1.6822717132568359; test_loss=1.9283376121520996\n",
      "save model\n",
      "epoch = 31; train_loss = 1.7011713604927063; test_loss=2.051430959701538\n",
      "epoch = 32; train_loss = 1.676372208595276; test_loss=1.8888280248641969\n",
      "save model\n",
      "epoch = 33; train_loss = 1.5911961469650269; test_loss=1.9248469734191895\n",
      "save model\n",
      "epoch = 34; train_loss = 1.555298951625824; test_loss=1.8535078477859497\n",
      "save model\n",
      "epoch = 35; train_loss = 1.5971766548156738; test_loss=1.8740257215499878\n",
      "epoch = 36; train_loss = 1.5265616705417633; test_loss=1.9523182535171508\n",
      "save model\n",
      "epoch = 37; train_loss = 1.5634071674346923; test_loss=1.9211207580566407\n",
      "epoch = 38; train_loss = 1.467930414199829; test_loss=1.8848335552215576\n",
      "save model\n",
      "epoch = 39; train_loss = 1.487122938156128; test_loss=1.9059937381744385\n",
      "epoch = 40; train_loss = 1.4745361557006835; test_loss=2.083241300582886\n",
      "epoch = 41; train_loss = 1.5298062086105346; test_loss=1.9812708711624145\n",
      "epoch = 42; train_loss = 1.4818803477287292; test_loss=1.8989638519287109\n",
      "epoch = 43; train_loss = 1.4337703113555909; test_loss=1.937519588470459\n",
      "save model\n",
      "epoch = 44; train_loss = 1.465464376449585; test_loss=1.9650195455551147\n",
      "epoch = 45; train_loss = 1.4174617781639098; test_loss=1.941797890663147\n",
      "save model\n",
      "epoch = 46; train_loss = 1.4679245533943177; test_loss=1.9259123229980468\n",
      "epoch = 47; train_loss = 1.386378846168518; test_loss=2.0126863813400266\n",
      "save model\n",
      "epoch = 48; train_loss = 1.4289803295135497; test_loss=1.925683536529541\n",
      "epoch = 49; train_loss = 1.4104648883342743; test_loss=1.9768696308135987\n",
      "epoch = 0; train_loss = 270.84964126586914; test_loss=261.5194787597656\n",
      "save model\n",
      "epoch = 1; train_loss = 239.13860375976563; test_loss=233.47811950683592\n",
      "save model\n",
      "epoch = 2; train_loss = 212.41779843139648; test_loss=204.55343627929688\n",
      "save model\n",
      "epoch = 3; train_loss = 184.92359991455078; test_loss=179.80905334472655\n",
      "save model\n",
      "epoch = 4; train_loss = 162.24312957763672; test_loss=157.8327786254883\n",
      "save model\n",
      "epoch = 5; train_loss = 141.6759503326416; test_loss=137.54308013916017\n",
      "save model\n",
      "epoch = 6; train_loss = 122.89235122680664; test_loss=119.07809661865234\n",
      "save model\n",
      "epoch = 7; train_loss = 106.07515741729736; test_loss=102.65913421630859\n",
      "save model\n",
      "epoch = 8; train_loss = 91.08688330841065; test_loss=87.96238464355469\n",
      "save model\n",
      "epoch = 9; train_loss = 77.70240068817138; test_loss=74.88251556396484\n",
      "save model\n",
      "epoch = 10; train_loss = 65.83755082321167; test_loss=63.276543884277345\n",
      "save model\n",
      "epoch = 11; train_loss = 55.36463291168213; test_loss=53.00118003845215\n",
      "save model\n",
      "epoch = 12; train_loss = 46.164104097366334; test_loss=44.00577980041504\n",
      "save model\n",
      "epoch = 13; train_loss = 38.12611694526672; test_loss=36.13631805419922\n",
      "save model\n",
      "epoch = 14; train_loss = 31.149887784957887; test_loss=29.353839645385744\n",
      "save model\n",
      "epoch = 15; train_loss = 25.116504817962646; test_loss=23.45786334991455\n",
      "save model\n",
      "epoch = 16; train_loss = 19.97890629196167; test_loss=18.485505256652832\n",
      "save model\n",
      "epoch = 17; train_loss = 15.619411441326141; test_loss=14.282537212371826\n",
      "save model\n",
      "epoch = 18; train_loss = 11.99809689426422; test_loss=10.84473035812378\n",
      "save model\n",
      "epoch = 19; train_loss = 9.05307580089569; test_loss=8.085952701568603\n",
      "save model\n",
      "epoch = 20; train_loss = 6.708537474632263; test_loss=5.903380088806152\n",
      "save model\n",
      "epoch = 21; train_loss = 4.89021585226059; test_loss=4.280813484191895\n",
      "save model\n",
      "epoch = 22; train_loss = 3.554063632488251; test_loss=3.11041298866272\n",
      "save model\n",
      "epoch = 23; train_loss = 2.6161449337005616; test_loss=2.321197648048401\n",
      "save model\n",
      "epoch = 24; train_loss = 1.9833398554325103; test_loss=1.7614169025421142\n",
      "save model\n",
      "epoch = 25; train_loss = 1.538013730764389; test_loss=1.3799361896514892\n",
      "save model\n",
      "epoch = 26; train_loss = 1.227667366027832; test_loss=1.1132448887825013\n",
      "save model\n",
      "epoch = 27; train_loss = 1.0047867479324342; test_loss=0.9232777118682861\n",
      "save model\n",
      "epoch = 28; train_loss = 0.8449593293666839; test_loss=0.782246630191803\n",
      "save model\n",
      "epoch = 29; train_loss = 0.7235801882743835; test_loss=0.6734609484672547\n",
      "save model\n",
      "epoch = 30; train_loss = 0.6278707728385925; test_loss=0.5862577891349793\n",
      "save model\n",
      "epoch = 31; train_loss = 0.5524702265262603; test_loss=0.5216211128234863\n",
      "save model\n",
      "epoch = 32; train_loss = 0.49309464025497435; test_loss=0.47052006483078\n",
      "save model\n",
      "epoch = 33; train_loss = 0.4429326286315918; test_loss=0.4308346652984619\n",
      "save model\n",
      "epoch = 34; train_loss = 0.40531062030792236; test_loss=0.41112781286239625\n",
      "save model\n",
      "epoch = 35; train_loss = 0.37152919673919677; test_loss=0.3682045793533325\n",
      "save model\n",
      "epoch = 36; train_loss = 0.3369327380657196; test_loss=0.3472240149974823\n",
      "save model\n",
      "epoch = 37; train_loss = 0.31694122064113617; test_loss=0.3166473650932312\n",
      "save model\n",
      "epoch = 38; train_loss = 0.2977993643283844; test_loss=0.2909129512310028\n",
      "save model\n",
      "epoch = 39; train_loss = 0.27863330507278444; test_loss=0.2809227156639099\n",
      "save model\n",
      "epoch = 40; train_loss = 0.25951165485382083; test_loss=0.27170642614364626\n",
      "save model\n",
      "epoch = 41; train_loss = 0.24867163825035096; test_loss=0.2522967350482941\n",
      "save model\n",
      "epoch = 42; train_loss = 0.23326582527160644; test_loss=0.24823246717453004\n",
      "save model\n",
      "epoch = 43; train_loss = 0.22341941595077514; test_loss=0.24005813121795655\n",
      "save model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 44; train_loss = 0.21436585927009583; test_loss=0.24203043699264526\n",
      "save model\n",
      "epoch = 45; train_loss = 0.21065219950675965; test_loss=0.23612891793251037\n",
      "save model\n",
      "epoch = 46; train_loss = 0.20425519359111785; test_loss=0.22381652116775513\n",
      "save model\n",
      "epoch = 47; train_loss = 0.1937833170890808; test_loss=0.21141630709171294\n",
      "save model\n",
      "epoch = 48; train_loss = 0.18874652922153473; test_loss=0.21617799162864684\n",
      "save model\n",
      "epoch = 49; train_loss = 0.1877949196100235; test_loss=0.204817174077034\n",
      "save model\n"
     ]
    }
   ],
   "source": [
    "# load files\n",
    "import pickle\n",
    "# Load in data\n",
    "shape_list = ['triangle', 'bean', 'torus1', 'torus2']\n",
    "percent_list = ['0.1', '0.5']\n",
    "\n",
    "for shape in shape_list:\n",
    "    for percent in percent_list:\n",
    "        \n",
    "        print(shape, percent, '-'*100)\n",
    "\n",
    "        with open(f'./datasets_generated/dataset_geometry_percentage/dataset_{shape}_{percent}_1200.pkl', 'rb') as file:\n",
    "            generated_dataset = pickle.load(file)\n",
    "\n",
    "        # at 20% sampling\n",
    "\n",
    "        coordinates, a_features, u_features, a_u_pairs = generated_dataset\n",
    "\n",
    "        # scale up u features to avoid numerical errors\n",
    "        u_features = u_features*10000\n",
    "\n",
    "        # ensure all the same dtype\n",
    "        coordinates = coordinates.to(torch.float32)\n",
    "        a_features = a_features.to(torch.float32)\n",
    "        u_features = u_features.to(torch.float32)\n",
    "\n",
    "        # split by train and test\n",
    "\n",
    "        N_train = 1000\n",
    "        N_test = 200\n",
    "        N_val = 0\n",
    "\n",
    "        coordinates_train = coordinates[:N_train]\n",
    "        a_features_train = a_features[:N_train]\n",
    "        u_features_train = u_features[:N_train]\n",
    "\n",
    "        # used in INR and MLP training\n",
    "        coordinates_test = coordinates[N_train:N_train+N_test]\n",
    "        a_features_test = a_features[N_train:N_train+N_test]\n",
    "        u_features_test = u_features[N_train:N_train+N_test]\n",
    "\n",
    "        # unseen data\n",
    "        coordinates_val = coordinates[N_train+N_test:N_train+N_test+N_val]\n",
    "        a_features_val = a_features[N_train+N_test:N_train+N_test+N_val]\n",
    "        u_features_val = u_features[N_train+N_test:N_train+N_test+N_val]\n",
    "\n",
    "        # specify dimension of code\n",
    "        latent_dim = 128\n",
    "\n",
    "        # use torch Dataset format\n",
    "        a_train_dataset = FunctionDataset(coordinates_train, a_features_train, latent_dim)\n",
    "        a_test_dataset = FunctionDataset(coordinates_test, a_features_test, latent_dim)\n",
    "        a_val_dataset = FunctionDataset(coordinates_val, a_features_val, latent_dim)\n",
    "\n",
    "        u_train_dataset = FunctionDataset(coordinates_train, u_features_train, latent_dim)\n",
    "        u_test_dataset = FunctionDataset(coordinates_test, u_features_test, latent_dim)\n",
    "        u_val_dataset = FunctionDataset(coordinates_val, u_features_val, latent_dim)\n",
    "\n",
    "        # Train the input INR\n",
    "\n",
    "        Train_SIREN_INR(a_train_dataset, a_test_dataset, latent_dim, f'{shape}_input_{percent}_SIREN_INR', epochs=50)\n",
    "\n",
    "        # Train the output INR\n",
    "\n",
    "        Train_SIREN_INR(u_train_dataset, u_test_dataset, latent_dim, f'{shape}_output_{percent}_SIREN_INR', epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "shape = 'torus2'\n",
    "percent = '0.5'\n",
    "\n",
    "with open(f'./datasets_generated/dataset_geometry_percentage/dataset_{shape}_{percent}_1200.pkl', 'rb') as file:\n",
    "            generated_dataset = pickle.load(file)\n",
    "\n",
    "coordinates, a_features, u_features, a_u_pairs = generated_dataset\n",
    "\n",
    "# scale up u features to avoid numerical errors\n",
    "u_features = u_features*10000\n",
    "\n",
    "# ensure all the same dtype\n",
    "coordinates = coordinates.to(torch.float32)\n",
    "a_features = a_features.to(torch.float32)\n",
    "u_features = u_features.to(torch.float32)\n",
    "\n",
    "# split by train and test\n",
    "\n",
    "N_train = 1000\n",
    "N_test = 200\n",
    "N_val = 0\n",
    "\n",
    "coordinates_train = coordinates[:N_train]\n",
    "a_features_train = a_features[:N_train]\n",
    "u_features_train = u_features[:N_train]\n",
    "\n",
    "# used in INR and MLP training\n",
    "coordinates_test = coordinates[N_train:N_train+N_test]\n",
    "a_features_test = a_features[N_train:N_train+N_test]\n",
    "u_features_test = u_features[N_train:N_train+N_test]\n",
    "\n",
    "# unseen data\n",
    "coordinates_val = coordinates[N_train+N_test:N_train+N_test+N_val]\n",
    "a_features_val = a_features[N_train+N_test:N_train+N_test+N_val]\n",
    "u_features_val = u_features[N_train+N_test:N_train+N_test+N_val]\n",
    "\n",
    "# specify dimension of code\n",
    "latent_dim = 128\n",
    "\n",
    "# use torch Dataset format\n",
    "a_train_dataset = FunctionDataset(coordinates_train, a_features_train, latent_dim)\n",
    "a_test_dataset = FunctionDataset(coordinates_test, a_features_test, latent_dim)\n",
    "a_val_dataset = FunctionDataset(coordinates_val, a_features_val, latent_dim)\n",
    "\n",
    "u_train_dataset = FunctionDataset(coordinates_train, u_features_train, latent_dim)\n",
    "u_test_dataset = FunctionDataset(coordinates_test, u_features_test, latent_dim)\n",
    "u_val_dataset = FunctionDataset(coordinates_val, u_features_val, latent_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DXY8Ifu-KjVD",
    "outputId": "aa162e83-78e2-4a42-e2bc-d9a6e38ef31a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    }
   ],
   "source": [
    "# extract the encodings by using the inner loop \n",
    "import torch\n",
    "input_INR_name = f'./INR_models_trained/{shape}_input_{percent}_SIREN_INR.pt'\n",
    "\n",
    "z_train_a = ExtractEncoding(input_INR_name, a_train_dataset)\n",
    "z_test_a = ExtractEncoding(input_INR_name, a_test_dataset)\n",
    "#z_val_a = ExtractEncoding(input_INR_name, a_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlRp926sOkmN",
    "outputId": "cc5f87aa-a27f-40cf-a3df-771de120f071"
   },
   "outputs": [],
   "source": [
    "output_INR_name = f'./INR_models_trained/{shape}_output_{percent}_SIREN_INR.pt'\n",
    "\n",
    "z_train_u = ExtractEncoding(output_INR_name, u_train_dataset)\n",
    "z_test_u = ExtractEncoding(output_INR_name, u_test_dataset)\n",
    "#z_val_u = ExtractEncoding(output_INR_name, u_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wUnVKZxlRXtY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CO0njFtqPghJ"
   },
   "outputs": [],
   "source": [
    "# extract statistics from train_data for z-score normalisation\n",
    "z_train_a_mean = z_train_a.mean(axis=0)\n",
    "z_train_a_std = z_train_a.std(axis=0)\n",
    "\n",
    "z_train_a_normalised = (z_train_a - z_train_a_mean)/z_train_a_std\n",
    "z_test_a_normalised = (z_test_a - z_train_a_mean)/z_train_a_std\n",
    "#z_val_a_normalised = (z_val_a - z_train_a_mean)/z_train_a_std\n",
    "\n",
    "\n",
    "z_train_u_mean = z_train_u.mean(axis=0)\n",
    "z_train_u_std = z_train_u.std(axis=0)\n",
    "\n",
    "z_train_u_normalised = (z_train_u - z_train_u_mean)/z_train_u_std\n",
    "z_test_u_normalised = (z_test_u - z_train_u_mean)/z_train_u_std\n",
    "#z_val_u_normalised = (z_val_u - z_train_u_mean)/z_train_u_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "model = LatentCodeMLP(latent_dim=latent_dim, hidden_dim=64, num_layers=3)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "trained_model, train_losses, test_losses = train_latent_code_mlp(\n",
    "    model=model,\n",
    "    dataset_a_train=z_train_a_normalised,\n",
    "    dataset_u_train=z_train_u_normalised,\n",
    "    dataset_a_test=z_test_a_normalised,\n",
    "    dataset_u_test=z_test_u_normalised,\n",
    "    latent_dim=latent_dim,\n",
    "    epochs=500,\n",
    "    lr=1e-4,\n",
    "    batch_size=batch_size,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training and Testing Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trained_model, train_losses, test_losses = train_latent_code_mlp(\n",
    "    model=trained_model,\n",
    "    dataset_a_train=z_train_a_normalised,\n",
    "    dataset_u_train=z_train_u_normalised,\n",
    "    dataset_a_test=z_test_a_normalised,\n",
    "    dataset_u_test=z_test_u_normalised,\n",
    "    latent_dim=latent_dim,\n",
    "    epochs=500,\n",
    "    lr=1e-4,\n",
    "    batch_size=batch_size,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training and Testing Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting transformed latent into output function (inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformed_z_a = (trained_model(z_train_a_normalised)*z_train_u_std) + z_train_u_mean # approximation of z_u train\n",
    "test_transformed_z_a = (trained_model(z_test_a_normalised)*z_train_u_std) + z_train_u_mean # approximation of z_u test\n",
    "#val_transformed_z_a = (trained_model(z_val_a_normalised)*z_train_u_std) + z_train_u_mean # approximation of z_u test\n",
    "\n",
    "# these are now the codes for the INR which will make the output function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# EXTRACT THE CODES FROM INPUT INR\n",
    "\n",
    "best_model = torch.load(output_INR_name)\n",
    "\n",
    "siren_model = best_model['inr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def VisualisePredictions(i, plots=True):\n",
    "    \n",
    "    N=64\n",
    "    \n",
    "    # Create 64 equally spaced points in the range [0, 1]\n",
    "    grid_points = torch.linspace(0, 1, N)\n",
    "\n",
    "    # Create the meshgrid\n",
    "    x, y = torch.meshgrid(grid_points, grid_points, indexing='ij')\n",
    "\n",
    "    # Stack the x and y coordinates along a new dimension\n",
    "    grid = torch.stack((x, y), dim=-1)\n",
    "    mask = mask_generator(N, shape).astype(bool)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Forward pass through the SIREN model\n",
    "        modulations = test_transformed_z_a[i].unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # generate z from the model\n",
    "        z_predictions = siren_model.modulated_forward(grid, modulations).squeeze().detach()*mask\n",
    "        z_predictions = z_predictions.numpy()\n",
    "\n",
    "    #--------------------------------------------------------------\n",
    "\n",
    "    z_ground_u = 10000*a_u_pairs[1000+i][1]\n",
    "    z_ground_a = a_u_pairs[1000+i][0]\n",
    "    \n",
    "    rel_error = abs((z_ground_u-z_predictions)/z_ground_u)\n",
    "    mean_rel_error = np.mean(rel_error[~np.isnan(rel_error)])\n",
    "\n",
    "    if plots:\n",
    "        # Plot true vs predicted\n",
    "        plt.figure(figsize=(18, 6))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(\"Ground Truth\")\n",
    "        plt.imshow(z_ground_u, cmap=\"viridis\", extent=(0, 64, 0, 64))\n",
    "        plt.colorbar(label=\"Value\")\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(\"Prediction\")\n",
    "        plt.imshow(z_predictions, cmap=\"viridis\", extent=(0, 64, 0, 64))\n",
    "        plt.colorbar(label=\"Value\")\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(\"rel. error\")\n",
    "        plt.imshow(rel_error, cmap=\"viridis\", extent=(0, 64, 0, 64))\n",
    "        plt.colorbar(label=\"Value\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(mean_rel_error)\n",
    "    \n",
    "    return mean_rel_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_rel_errors = []\n",
    "\n",
    "for i in range(200):\n",
    "    print(i)\n",
    "    mean_rel_errors.append(VisualisePredictions(i, plots=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shape, percent)\n",
    "\n",
    "print(np.mean(mean_rel_errors))\n",
    "print(np.median(mean_rel_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.hist(mean_rel_errors, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
